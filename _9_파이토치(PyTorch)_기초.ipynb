{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Xx-jP92OgP"
      },
      "source": [
        "# 파이토치(PyTorch)\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n",
        "\n",
        "- 코드 출처: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cxreguz2sL0"
      },
      "source": [
        "## 파이토치의 구성요소\n",
        "\n",
        "- `torch`: 텐서를 생성하는 라이브러리\n",
        "\n",
        "- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.nn`: 신경망을 생성하는 라이브러리\n",
        "\n",
        "- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n",
        "\n",
        "- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n",
        "\n",
        "- `torch.onnx`: ONNX(Open Neural Network Exchange)\n",
        "\n",
        "  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5O_aSvtHvb"
      },
      "source": [
        "## 텐서(Tensors)\n",
        "- 넘파이(NumPy)의 ndarray와 유사\n",
        "\n",
        "- GPU를 사용한 연산 가속도 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CmKIvnx0s8G6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "49IHV-qJE5FI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.7.1'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUHVy-gtZeT"
      },
      "source": [
        "### 초기화 되지 않은 행렬 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3PqY3cZatU0D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCIJ2pNteZv"
      },
      "source": [
        "### 무작위로 초기화된 행렬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h6oPj2Q9tdYx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1364, 0.4878],\n",
            "        [0.1146, 0.3116],\n",
            "        [0.7900, 0.3541],\n",
            "        [0.5430, 0.9910]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5aHphIHtiJk"
      },
      "source": [
        "### dtype이 long, 0으로 채워진 텐서"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(4, 2, dtype=torch.long)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W4VL8C_ctu8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.0000, 2.3000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([3, 2.3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4RmVBVtIt46M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 4, dtype=torch.double)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xxskTUfGuPUe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn_like(x, dtype=torch.float) # x 모양은 그대로 가져오되, 랜덤으로 채움\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5sGxGvucpH"
      },
      "source": [
        "### 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yy-JbqKEuYIR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(x.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehOg0eDwufru"
      },
      "source": [
        "## 텐서의 연산(operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Doc_37uh3G"
      },
      "source": [
        "### 덧셈 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rw4JCYkYuef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wa44ur1Nuj5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6724, 0.2491, 0.0728, 0.8664],\n",
            "        [0.7221, 0.4772, 0.3406, 0.5142]])\n",
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(2, 4)\n",
        "print(y)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5gcOo-Ouo9B"
      },
      "source": [
        "### 덧셈2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Qx-NzJhhumZx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvrQhLuuuIr"
      },
      "source": [
        "### 덧셈3\n",
        "- 결과 텐서를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lUsLAOTcur1-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(2, 4)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BdyZFSu2Ei"
      },
      "source": [
        "### 덧셈4\n",
        "- `in-place` 방식\n",
        "\n",
        "- (참고) in-place 방식\n",
        "  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n",
        "  - `x.copy_(y), x.t_()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lu8rR4WVu0wQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n",
            "tensor([[0.6724, 0.2491, 0.0728, 0.8664],\n",
            "        [0.7221, 0.4772, 0.3406, 0.5142]])\n",
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "print(y)\n",
        "y.add_(x) # y += x\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8nsrGjOw6W"
      },
      "source": [
        "### 그 외의 연산\n",
        "- `torch.sub` : 뺄셈\n",
        "\n",
        "- `torch.mul` : 곱셉\n",
        "\n",
        "- `torch.div` : 나눗셈\n",
        "\n",
        "- `torch.mm` : 내적(dot product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S51kxzPTO1ER"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ou0dY8mkPR24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6RlZZBp3PbE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7MR-ofE5P7VC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[20., 28.],\n",
            "        [52., 76.]])\n"
          ]
        }
      ],
      "source": [
        "# 행렬 곱\n",
        "\n",
        "x = torch.Tensor([[1, 3],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(torch.mm(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URGwHE_NjDi"
      },
      "source": [
        "## 텐서의 조작(manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCsdZIPTvG53"
      },
      "source": [
        "### 인덱싱\n",
        "- 넘파이처럼 인덱싱 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jF2DE8kzvOs3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [5., 7.]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GQtBH3r3u7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 7.])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEscXddKvQ5l"
      },
      "source": [
        "### view\n",
        "- 텐서의 크기(size)나 모양(shape)을 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xwhWeqhLvKKj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 5])\n",
            "torch.Size([20])\n",
            "torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 5)\n",
        "y = x.view(20)\n",
        "z = x.view(5, -1)\n",
        "\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBY_wuIRvf5j"
      },
      "source": [
        "### item\n",
        "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "E0W24QqpvcmV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.5796])\n",
            "-0.5796216130256653\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # item은 실제 존재하는 값을 출력\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1sCUVwC3Nua"
      },
      "source": [
        "- 스칼라값 하나만 존재해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jl4_FAgd3Lt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0163, -0.5312])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-7c023f92a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThndsy5M6wM"
      },
      "source": [
        "### squeeze \n",
        "- 차원을 축소(제거)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OF3rOavnRxgM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Y2jq0jHJR5Jw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9965, 0.4982, 0.9327],\n",
            "        [0.1674, 0.9794, 0.7687],\n",
            "        [0.4964, 0.0900, 0.7723]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.squeeze()\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv-dnTYNJ8Z"
      },
      "source": [
        "### unsqueeze\n",
        "- 차원을 증가(생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PFxaHGY1NOBo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0.0090, 0.3771, 0.2244],\n",
            "         [0.4832, 0.5697, 0.9270],\n",
            "         [0.1131, 0.1186, 0.2343]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "b6sa4tJ7SA8G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0090, 0.3771, 0.2244],\n",
            "          [0.4832, 0.5697, 0.9270],\n",
            "          [0.1131, 0.1186, 0.2343]]]])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.unsqueeze(dim=0)\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_oa9JANOa6"
      },
      "source": [
        "### stack\n",
        "- 텐서간 결합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "f3x_XaUYNOuc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([1,4])\n",
        "y = torch.FloatTensor([2,5])\n",
        "z = torch.FloatTensor([3,6])\n",
        "\n",
        "print(torch.stack([x, y, z]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJscbfg35-c"
      },
      "source": [
        "### cat\n",
        "- 텐서를 결합하는 메소드(concatenate)\n",
        "\n",
        "- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n",
        "  - 예를 들어, 해당 차원을 늘려준 후 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Mv3zlaNm37P1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.1752,  0.1866, -1.5733],\n",
            "          [ 0.6942, -0.3779,  1.4861],\n",
            "          [-0.6168, -0.2004,  0.5868]]],\n",
            "\n",
            "\n",
            "        [[[-0.5854,  0.0159, -0.9685],\n",
            "          [-0.4702,  2.1106, -0.7855],\n",
            "          [ 1.2723,  0.2302,  0.5311]]]])\n",
            "torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.3662,  1.5685, -0.0570],\n",
            "          [ 1.1396, -0.0481,  0.2125],\n",
            "          [ 0.0467,  1.5326, -1.4442]]],\n",
            "\n",
            "\n",
            "        [[[-1.7959,  0.3558,  0.7515],\n",
            "          [ 1.7988, -0.6035, -0.1324],\n",
            "          [-0.0990,  0.0146,  0.8388]]]])\n",
            "torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "69M5jY60S7Mi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.3882,  0.8124, -0.2160],\n",
            "         [-1.5805, -0.0826,  0.8876],\n",
            "         [-0.1478,  0.7554,  0.2387],\n",
            "         [ 0.6822,  1.2933,  1.1244],\n",
            "         [-0.0926,  0.5437, -0.0403],\n",
            "         [-1.2582, -0.4290, -1.2237]]])\n",
            "torch.Size([1, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 3, 3)\n",
        "b = torch.randn(1, 3, 3)\n",
        "c = torch.cat((a, b), dim=1)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGXnOAqQTmG"
      },
      "source": [
        "### chuck\n",
        "- 텐서를 여러 개로 나눌 때 사용\n",
        "\n",
        "- 몇 개의 텐서로 나눌 것이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pNV80VzPQZgG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1922, 0.7639, 0.9714, 0.9910, 0.5425, 0.6984],\n",
            "        [0.0602, 0.0840, 0.4190, 0.2966, 0.7102, 0.1967],\n",
            "        [0.0583, 0.5205, 0.8379, 0.5632, 0.2177, 0.3999]])\n",
            "tensor([[0.1922, 0.7639],\n",
            "        [0.0602, 0.0840],\n",
            "        [0.0583, 0.5205]])\n",
            "tensor([[0.9714, 0.9910],\n",
            "        [0.4190, 0.2966],\n",
            "        [0.8379, 0.5632]])\n",
            "tensor([[0.5425, 0.6984],\n",
            "        [0.7102, 0.1967],\n",
            "        [0.2177, 0.3999]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.chunk(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Qb0jWQgm-"
      },
      "source": [
        "### split\n",
        "- `chunck`와 동일한 기능이지만 조금 다름\n",
        "\n",
        "- 하나의 텐서당 크기가 얼마이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7099, 0.3394, 0.4006, 0.7464, 0.6270, 0.2052],\n",
            "        [0.7251, 0.9333, 0.6631, 0.1988, 0.6035, 0.5055],\n",
            "        [0.6480, 0.6004, 0.9905, 0.1201, 0.4180, 0.3201]])\n",
            "tensor([[0.7099, 0.3394, 0.4006],\n",
            "        [0.7251, 0.9333, 0.6631],\n",
            "        [0.6480, 0.6004, 0.9905]])\n",
            "tensor([[0.7464, 0.6270, 0.2052],\n",
            "        [0.1988, 0.6035, 0.5055],\n",
            "        [0.1201, 0.4180, 0.3201]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2 = torch.split(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1V6DDnLVQqxz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1180, 0.4988, 0.5982, 0.1992, 0.6785, 0.8217],\n",
            "        [0.4125, 0.5807, 0.6859, 0.2323, 0.2702, 0.6624],\n",
            "        [0.5821, 0.0659, 0.2783, 0.1323, 0.2304, 0.6171]])\n",
            "tensor([[0.1180, 0.4988],\n",
            "        [0.4125, 0.5807],\n",
            "        [0.5821, 0.0659]])\n",
            "tensor([[0.5982, 0.1992],\n",
            "        [0.6859, 0.2323],\n",
            "        [0.2783, 0.1323]])\n",
            "tensor([[0.6785, 0.8217],\n",
            "        [0.2702, 0.6624],\n",
            "        [0.2304, 0.6171]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.split(tensor, 2, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estSwhCgvta6"
      },
      "source": [
        "### torch ↔ numpy\n",
        "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
        "\n",
        "  - `numpy()`\n",
        "  - `from_numpy()`\n",
        "\n",
        "- (참고)\n",
        "  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VxHI7c_yvmAT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(7)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "whbrhokHwJ3A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "b = a.numpy()\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5StIhUWDwQjA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4., 4., 4., 4., 4., 4., 4.])\n",
            "[4. 4. 4. 4. 4. 4. 4.]\n"
          ]
        }
      ],
      "source": [
        "a.add_(1) # a에다 1이 더해짐\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3RNS5-cRwTt8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(7)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZaxSvLxEej"
      },
      "source": [
        "## CUDA Tensors\n",
        "- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
        "  - 예) cpu, gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xkaQznCRxpUj"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SCnC0x2Rxpbk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6348])\n",
            "0.634801983833313\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GcSsFLkDw-nI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "tensor([1.6348], device='cuda:0')\n",
            "tensor([1.6348], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device) # 만들어진 x를 gpu로 옮기겠다\n",
        "z = x + y\n",
        "print(device)\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## AUTOGRAD (자동미분)\n",
        "- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "\n",
        "- backprop를 위한 미분값을 자동으로 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "### Tensor\n",
        "\n",
        "- data: tensor형태의 데이터\n",
        "\n",
        "- grad: data가 겨쳐온 layer에 대한 미분값 저장\n",
        "\n",
        "- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
        "\n",
        "- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n",
        "\n",
        "- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n",
        "\n",
        "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
        "\n",
        "- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ipdk_1jfx47I"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ljNU-r9p0Rpo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "or6sQ4EB0UYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 5 # by broadcast\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PuQ7xDmu0Wpj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x0000022547F68588>\n"
          ]
        }
      ],
      "source": [
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6_2iM-Zq0ZdG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[72., 72., 72.],\n",
            "        [72., 72., 72.],\n",
            "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 2\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHGROgrM0ebO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x0000022547F68748>\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 3)\n",
        "a = ((a * 3) / (a- 1))\n",
        "print(a.requires_grad)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)\n",
        "- 역전파: `.backward()`를 통해 역전파 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1tdoN9p-1kn4"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CixGTXbV1B9p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SY63Mcc-1iNI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1352.9348, -569.2090,  882.2342], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YPaVAbIT3gx_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v) # y를 backward 할 때 v를 넣음\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "weeIe5_Z3jVe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ALcth7Ew3l7H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(1)\n",
        "- 계산 흐름  \n",
        "  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "<br>\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해  \n",
        "  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n",
        "    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NUAc1etP3oBc"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tCW7dq9uB89T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-AyyGy49FLz9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SmmJa-hvFPGH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad: None\n",
            "a.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"a.data:\",a.data)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\",a.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "- $b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iUPt042iF9V1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "b = a + 2\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "- $c = b^2$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FRDS6gP0GFZG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c = b**2\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VynoiUywGSwh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v3ryJon9GeMn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out)\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "- a의 `grad_fn`이 None인 이유  \n",
        "  직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bccI4vIWGgqj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "a.grad: tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"a.data:\",a.data)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\",a.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oka1mkadHq-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b.data: tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "b.grad: None\n",
            "b.grad_fn: <AddBackward0 object at 0x00000225480DD278>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"b.data:\", b.data)\n",
        "print(\"b.grad:\", b.grad)\n",
        "print(\"b.grad_fn:\",b.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZiYNajdLccUF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c.data: tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "c.grad: None\n",
            "c.grad_fn: <PowBackward0 object at 0x00000225480DC9B0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"c.data:\", c.data)\n",
        "print(\"c.grad:\", c.grad)\n",
        "print(\"c.grad_fn:\",c.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BcLoMYite0vU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out.data: tensor(36.)\n",
            "out.grad: None\n",
            "out.grad_fn: <SumBackward0 object at 0x00000225480DC710>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"out.data:\", out.data)\n",
        "print(\"out.grad:\", out.grad)\n",
        "print(\"out.grad_fn:\", out.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXgwviHfovj"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(2)\n",
        "- `grad`값을 넣어서 `backward`\n",
        "\n",
        "- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bB6DCYXRfcI_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "y = (x ** 2)\n",
        "z = y ** 2 + x\n",
        "out = z.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AVo-glm8fvFv"
      },
      "outputs": [],
      "source": [
        "grad = torch.Tensor([0.1, 1, 100])\n",
        "z.backward(grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tdBklrepf2qq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.data: tensor([1., 1., 1.])\n",
            "x.grad: tensor([  0.5000,   5.0000, 500.0000])\n",
            "x.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"x.data:\", x.data)\n",
        "print(\"x.grad:\", x.grad)\n",
        "print(\"x.grad_fn:\", x.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HQvUGlfRf7jU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y.data: tensor([1., 1., 1.])\n",
            "y.grad: None\n",
            "y.grad_fn: <PowBackward0 object at 0x0000022547F68A58>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"y.data:\", y.data)\n",
        "print(\"y.grad:\", y.grad)\n",
        "print(\"y.grad_fn:\", y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "h7TFHdMfgxvW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z.data: tensor([2., 2., 2.])\n",
            "z.grad: None\n",
            "z.grad_fn: <AddBackward0 object at 0x0000022547F682B0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"z.data:\", z.data)\n",
        "print(\"z.grad:\", z.grad)\n",
        "print(\"z.grad_fn:\", z.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv-osmNmWiA"
      },
      "source": [
        "## nn & nn.functional\n",
        "\n",
        "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
        "\n",
        "- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
        "\n",
        "- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n",
        "\n",
        "- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n",
        "  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8fkKq3nWP1"
      },
      "source": [
        "### nn 패키지\n",
        "\n",
        "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n",
        "  - 따라서, `weight`값들을 직접 선언 안함\n",
        "\n",
        "- 예시\n",
        "  - Containers\n",
        "\n",
        "  - Convolution Layers\n",
        "\n",
        "  - Pooling layers\n",
        "\n",
        "  - Padding Layers\n",
        "\n",
        "  - Non-linear Activations (weighted sum, nonlinearity)\n",
        "\n",
        "  - Non-linear Activations (other)\n",
        "\n",
        "  - Normalization Layers\n",
        "\n",
        "  - Recurrent Layers\n",
        "\n",
        "  - Transformer Layers\n",
        "\n",
        "  - Linear Layers\n",
        "\n",
        "  - Dropout Layers\n",
        "\n",
        "  - Sparse Layers\n",
        "\n",
        "  - Distance Functions\n",
        "\n",
        "  - Loss Functions\n",
        "\n",
        "  - ..\n",
        "- https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8tEtWHAsmZMy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjCbeEQqPSI"
      },
      "source": [
        "- Convolution Layer 예시 (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NQ7Y0tCOpkhM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 1.4765e+00,  1.8895e+00,  5.5056e-01,  ...,  7.1684e-01,\n",
            "            6.7973e-01,  2.4238e-01],\n",
            "          [-4.8798e-01, -1.1009e+00,  8.2104e-01,  ..., -1.2543e+00,\n",
            "           -1.3129e+00,  1.5883e+00],\n",
            "          [ 7.2743e-01,  9.5327e-01, -3.6087e-01,  ...,  8.6458e-02,\n",
            "           -4.5525e-01,  7.8782e-01],\n",
            "          ...,\n",
            "          [ 4.5550e-01,  3.8240e-01,  7.3699e-01,  ...,  1.1049e+00,\n",
            "           -8.4638e-02,  3.2192e-01],\n",
            "          [ 1.3633e+00,  5.6500e-01, -4.7841e-01,  ..., -1.6067e-01,\n",
            "            7.8214e-01,  1.5449e+00],\n",
            "          [-2.8770e-01, -1.3690e+00,  5.0007e-01,  ..., -1.0258e+00,\n",
            "            6.9032e-01, -6.5373e-01]],\n",
            "\n",
            "         [[-1.0770e+00,  8.0718e-01,  2.4569e-02,  ...,  1.1597e-01,\n",
            "           -2.1862e-01,  6.5634e-01],\n",
            "          [-9.6943e-01, -5.8904e-01,  1.6768e+00,  ...,  1.0266e+00,\n",
            "           -2.8646e-02,  6.2978e-01],\n",
            "          [ 7.7868e-01, -1.8944e-01, -9.7938e-01,  ...,  8.5489e-01,\n",
            "            7.0822e-01,  3.0647e-01],\n",
            "          ...,\n",
            "          [ 4.1498e-01, -4.8626e-01, -9.4322e-01,  ...,  3.0676e-01,\n",
            "           -5.7727e-01,  2.0951e+00],\n",
            "          [ 5.1802e-02,  1.1452e+00, -7.4172e-01,  ...,  1.4840e+00,\n",
            "           -5.2157e-01, -1.9988e+00],\n",
            "          [ 8.0093e-01, -6.5055e-01, -6.1924e-01,  ..., -6.7380e-01,\n",
            "           -6.5182e-01, -7.5380e-01]],\n",
            "\n",
            "         [[-1.0530e+00, -9.6421e-01,  1.2006e+00,  ...,  8.0166e-02,\n",
            "            9.8919e-01,  1.4976e+00],\n",
            "          [-7.4002e-01, -6.8106e-01, -1.3143e+00,  ...,  5.8387e-01,\n",
            "            5.9785e-01,  9.1610e-01],\n",
            "          [-1.4298e+00, -1.4345e+00,  5.7763e-01,  ...,  1.0163e+00,\n",
            "            2.5291e-01, -4.7001e-01],\n",
            "          ...,\n",
            "          [ 2.9379e+00,  1.9787e+00, -1.4718e+00,  ..., -4.8342e-01,\n",
            "           -1.2283e+00, -8.0810e-01],\n",
            "          [-6.2291e-01, -4.1501e-01,  1.7179e+00,  ..., -3.4698e-01,\n",
            "           -6.7125e-01,  1.0105e+00],\n",
            "          [ 1.4358e+00, -1.0040e+00, -5.5640e-01,  ...,  2.5311e-01,\n",
            "            1.4430e+00, -2.5685e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1238e-01,  2.3732e-01, -1.1391e+00,  ..., -2.1498e-01,\n",
            "            2.2501e+00, -1.6211e-01],\n",
            "          [ 8.1598e-01,  9.9962e-01,  9.8787e-01,  ..., -3.2452e+00,\n",
            "            6.2962e-01, -1.2641e+00],\n",
            "          [-2.3895e-01,  1.4836e+00,  5.9580e-02,  ..., -4.7162e-01,\n",
            "            1.1461e+00, -8.1054e-01],\n",
            "          ...,\n",
            "          [-1.7053e+00, -1.2200e+00,  1.3413e-01,  ...,  5.6710e-01,\n",
            "            1.5612e-01, -2.6989e-01],\n",
            "          [ 8.4981e-01, -3.2962e-01, -1.0542e+00,  ..., -1.4643e-01,\n",
            "            4.7265e-02, -1.4346e+00],\n",
            "          [ 8.0935e-01, -1.5030e+00, -1.5838e-01,  ...,  4.3244e-01,\n",
            "            3.2767e-01, -1.0061e+00]],\n",
            "\n",
            "         [[-3.2296e-01, -1.2883e+00, -2.4021e+00,  ..., -7.7186e-01,\n",
            "            6.9884e-01,  1.9277e-01],\n",
            "          [-1.4330e+00, -2.8485e-01, -1.8133e-01,  ..., -7.0554e-01,\n",
            "           -3.7750e-01, -1.6610e+00],\n",
            "          [ 1.7149e-01, -1.1242e+00,  3.5383e-01,  ..., -2.0781e-01,\n",
            "            8.2980e-01,  9.3979e-01],\n",
            "          ...,\n",
            "          [-4.2691e-01, -8.9597e-01,  1.7140e+00,  ...,  1.0009e+00,\n",
            "           -1.1376e+00, -1.2035e+00],\n",
            "          [-1.1080e+00,  8.1481e-01, -3.1004e-01,  ...,  1.1950e+00,\n",
            "            3.7561e-01,  6.7724e-01],\n",
            "          [ 2.2639e-01, -8.9664e-03, -1.0540e+00,  ...,  6.8697e-01,\n",
            "           -5.1070e-01, -1.6453e+00]],\n",
            "\n",
            "         [[-1.2697e+00, -9.6144e-01,  2.5876e-01,  ..., -7.7756e-02,\n",
            "            4.5056e-02, -4.3062e-01],\n",
            "          [-5.3306e-01,  1.0799e+00,  7.1923e-01,  ...,  6.8174e-01,\n",
            "            1.5060e-01,  7.9089e-01],\n",
            "          [-1.2646e-01, -1.7283e+00, -4.6115e-01,  ...,  1.0125e-01,\n",
            "            1.1132e+00,  1.6108e+00],\n",
            "          ...,\n",
            "          [ 1.6693e+00,  3.2250e-01, -1.2411e+00,  ..., -5.0569e-02,\n",
            "            5.4605e-01, -2.3826e-02],\n",
            "          [ 4.6678e-01,  1.1021e+00,  3.4785e-02,  ..., -2.6332e-01,\n",
            "            9.2679e-01, -6.3984e-01],\n",
            "          [ 1.5434e+00,  4.4988e-01, -2.8044e-01,  ...,  8.2946e-02,\n",
            "            1.4793e+00,  1.7856e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0746e-01,  1.2516e+00, -1.1632e+00,  ..., -1.5891e+00,\n",
            "            3.7208e-01, -1.0582e+00],\n",
            "          [-1.2417e-01, -3.4092e-01,  5.2235e-01,  ..., -1.3875e+00,\n",
            "            1.5658e+00, -5.8783e-01],\n",
            "          [-7.0212e-01,  1.5506e+00,  1.1882e+00,  ...,  4.9159e-01,\n",
            "           -1.3019e+00, -1.9496e-01],\n",
            "          ...,\n",
            "          [ 1.2375e+00,  1.1230e+00, -1.3947e+00,  ..., -4.4257e-01,\n",
            "            1.6956e+00, -1.0157e+00],\n",
            "          [ 3.0260e-02,  9.7299e-02, -2.1786e-02,  ...,  2.0624e+00,\n",
            "           -2.8435e-01,  1.1314e-01],\n",
            "          [-2.9405e-01,  1.5623e+00,  3.9409e-01,  ...,  2.4025e-01,\n",
            "           -8.5477e-01,  5.7340e-01]],\n",
            "\n",
            "         [[ 1.2209e+00, -7.3372e-01, -9.0213e-01,  ...,  2.7922e-01,\n",
            "            1.6380e-01, -5.5388e-01],\n",
            "          [-8.8577e-02, -4.4692e-01, -3.5535e-01,  ..., -7.2066e-01,\n",
            "            1.6778e+00, -5.1091e-01],\n",
            "          [ 1.6161e+00,  8.1610e-01, -1.9378e+00,  ..., -4.5089e-02,\n",
            "            5.0255e-01,  2.6241e-01],\n",
            "          ...,\n",
            "          [ 1.1198e+00,  4.3980e-01,  8.0221e-01,  ...,  3.4737e-01,\n",
            "            2.8474e+00,  2.6410e-01],\n",
            "          [ 4.5653e-01, -5.1316e-01, -4.3672e-01,  ...,  2.1920e+00,\n",
            "            3.9071e-01, -8.6096e-01],\n",
            "          [ 3.1642e-01,  4.0953e-01, -4.0580e-01,  ...,  8.6492e-01,\n",
            "           -1.2213e-01,  7.4311e-01]],\n",
            "\n",
            "         [[-5.6798e-01, -1.9814e-01,  5.9645e-01,  ..., -6.9085e-02,\n",
            "            1.0727e-01, -8.8448e-01],\n",
            "          [-4.9468e-01, -1.2497e+00,  1.5401e-01,  ...,  3.4462e-01,\n",
            "           -1.1109e+00, -8.1016e-01],\n",
            "          [ 4.6077e-01, -1.1036e+00, -1.6255e+00,  ..., -6.2022e-02,\n",
            "            4.2101e-01, -1.7269e-01],\n",
            "          ...,\n",
            "          [ 1.0031e+00, -3.5381e-01,  6.5945e-01,  ...,  7.1978e-01,\n",
            "            2.1655e+00, -3.5110e-01],\n",
            "          [-2.5749e+00,  9.0263e-01,  9.6331e-01,  ...,  1.3032e-01,\n",
            "           -5.2772e-01, -7.2472e-01],\n",
            "          [-1.2005e+00, -9.9344e-01, -1.7267e-01,  ...,  9.0477e-02,\n",
            "            6.3990e-01, -1.4111e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1156e-01,  8.2849e-01, -7.6392e-01,  ..., -5.5865e-01,\n",
            "            1.4950e-01, -4.1117e-02],\n",
            "          [ 2.3110e-01,  7.6900e-01, -1.6374e+00,  ...,  9.8841e-01,\n",
            "            1.1715e+00, -9.1469e-01],\n",
            "          [ 5.2082e-02, -1.3985e-01,  6.2365e-01,  ...,  9.9591e-01,\n",
            "            2.8694e-01,  6.2493e-01],\n",
            "          ...,\n",
            "          [ 2.3425e-01,  1.0021e-01,  3.0500e+00,  ...,  8.9322e-01,\n",
            "           -5.7952e-01, -5.8505e-01],\n",
            "          [-1.9782e+00,  2.0517e+00,  3.4672e-01,  ...,  9.0992e-01,\n",
            "            8.8445e-01, -7.5360e-01],\n",
            "          [-5.8473e-01, -5.8487e-01,  2.2410e+00,  ...,  5.5560e-01,\n",
            "            2.8210e-01,  1.2086e+00]],\n",
            "\n",
            "         [[ 3.8196e-02, -4.6354e-02,  2.7528e+00,  ..., -4.2795e-01,\n",
            "            1.8292e+00,  7.9053e-01],\n",
            "          [-6.4198e-01, -8.5647e-01, -3.8831e-01,  ..., -1.2536e+00,\n",
            "            2.0904e+00,  4.1293e-01],\n",
            "          [ 9.8928e-01,  1.7086e-01,  6.0594e-01,  ..., -6.4696e-01,\n",
            "            2.5372e+00,  3.9450e-01],\n",
            "          ...,\n",
            "          [-1.6599e+00,  9.7747e-01,  5.6257e-01,  ...,  2.6453e-01,\n",
            "            1.6291e-01, -5.2442e-01],\n",
            "          [ 1.4222e+00, -6.6415e-02,  6.6451e-01,  ..., -1.2640e+00,\n",
            "           -8.3710e-01, -2.0351e+00],\n",
            "          [ 8.6725e-01,  1.2764e+00, -2.6705e-01,  ..., -6.3981e-01,\n",
            "           -2.5150e-01, -5.8594e-01]],\n",
            "\n",
            "         [[-6.0134e-02, -3.0821e-01,  3.7415e-01,  ..., -7.1043e-01,\n",
            "            2.5072e+00,  1.6549e+00],\n",
            "          [-1.2933e+00,  1.1366e+00, -1.6666e+00,  ...,  6.5006e-01,\n",
            "            9.7127e-01,  1.1846e+00],\n",
            "          [ 6.4961e-02,  8.8625e-01,  6.7028e-01,  ..., -8.9335e-01,\n",
            "           -3.5845e-01,  1.3392e+00],\n",
            "          ...,\n",
            "          [ 6.2224e-01, -1.1078e+00, -9.0551e-01,  ..., -1.0957e+00,\n",
            "           -4.8074e-01,  2.9067e-01],\n",
            "          [ 3.5611e-01, -3.2783e-01,  1.9474e-02,  ...,  9.0366e-01,\n",
            "            1.8775e+00, -7.0045e-01],\n",
            "          [ 7.3793e-02,  4.9015e-02, -3.3628e-02,  ...,  6.2908e-01,\n",
            "           -1.5529e+00, -1.3402e+00]]],\n",
            "\n",
            "\n",
            "        [[[-6.3577e-01,  4.8262e-01,  6.6543e-01,  ..., -1.8255e+00,\n",
            "           -2.5533e-01, -2.5302e-01],\n",
            "          [-1.1409e+00, -5.9285e-01, -1.9766e+00,  ..., -1.3467e+00,\n",
            "            3.7915e-01,  8.9652e-01],\n",
            "          [ 7.4445e-01,  7.8400e-01,  1.1143e+00,  ...,  1.9555e+00,\n",
            "           -1.1004e+00, -5.4921e-01],\n",
            "          ...,\n",
            "          [ 8.8771e-01, -2.6940e-01, -1.3710e+00,  ...,  4.7760e-01,\n",
            "           -1.0340e+00,  1.3117e+00],\n",
            "          [-6.0874e-01, -4.0191e-01, -1.7012e-01,  ..., -1.2662e+00,\n",
            "            7.1094e-01, -7.4031e-01],\n",
            "          [ 1.3263e+00,  2.2201e-01,  1.9953e-01,  ...,  2.2986e+00,\n",
            "           -1.5497e+00, -6.8396e-01]],\n",
            "\n",
            "         [[-2.4341e-01,  1.0280e+00, -1.0249e-01,  ...,  8.9851e-01,\n",
            "            6.3569e-01,  2.7451e-01],\n",
            "          [ 3.1426e-01,  3.5742e-01,  7.4457e-01,  ..., -4.7614e-01,\n",
            "           -1.0231e+00,  2.9908e-01],\n",
            "          [ 6.9558e-01, -9.3651e-01, -1.7739e+00,  ..., -6.6123e-01,\n",
            "           -5.3019e-01, -4.5028e-01],\n",
            "          ...,\n",
            "          [-1.4838e+00, -1.1639e+00,  6.3217e-01,  ...,  1.6983e+00,\n",
            "            6.0383e-01,  7.4447e-01],\n",
            "          [-6.7646e-01,  1.2008e-01, -9.5815e-01,  ...,  3.9442e-01,\n",
            "           -1.9693e-01,  1.7098e+00],\n",
            "          [-5.5123e-01,  5.0916e-01,  3.3931e-01,  ...,  1.0145e-01,\n",
            "           -1.3606e+00,  1.9703e-01]],\n",
            "\n",
            "         [[-1.5788e+00, -1.4991e+00, -9.3723e-01,  ...,  1.3669e-01,\n",
            "            6.0603e-01,  1.0054e+00],\n",
            "          [ 3.0872e-01, -1.0938e-01,  6.7491e-01,  ..., -5.7028e-01,\n",
            "            1.5164e-01,  6.2330e-01],\n",
            "          [-4.7928e-02,  8.7751e-01,  2.1710e+00,  ..., -1.2433e+00,\n",
            "            3.9265e-01,  5.5917e-01],\n",
            "          ...,\n",
            "          [ 2.5373e-01, -8.6233e-01, -8.2549e-02,  ..., -1.0780e+00,\n",
            "            2.0134e-01, -5.7244e-01],\n",
            "          [-1.2638e+00,  5.7539e-01, -1.3550e-01,  ..., -2.5778e-02,\n",
            "           -4.8754e-02, -4.3766e-01],\n",
            "          [-1.5867e+00,  5.0945e-01, -2.3585e+00,  ...,  1.8431e+00,\n",
            "            3.1513e-01, -2.3111e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3848e-01,  4.4164e-01,  3.7055e-01,  ...,  5.1088e-01,\n",
            "           -3.5005e-01,  3.2693e-01],\n",
            "          [ 2.4429e-02,  3.1674e-01,  1.1195e+00,  ...,  1.3540e+00,\n",
            "            4.5630e-01, -1.4874e+00],\n",
            "          [-1.2678e+00, -1.1789e+00,  6.0300e-01,  ...,  1.0893e+00,\n",
            "           -7.3854e-02, -1.8834e-01],\n",
            "          ...,\n",
            "          [ 6.2027e-01,  2.1494e+00,  2.2533e-01,  ..., -1.6737e-01,\n",
            "            1.1669e+00,  3.1422e-01],\n",
            "          [-3.7795e-02, -1.3744e+00,  1.9251e-01,  ..., -2.0507e+00,\n",
            "            1.3287e+00,  1.0805e+00],\n",
            "          [ 2.1681e+00,  3.9842e-01, -9.2613e-01,  ...,  1.2706e-02,\n",
            "            7.3528e-02, -6.4236e-01]],\n",
            "\n",
            "         [[ 6.1898e-01, -2.9781e-03,  3.6807e-01,  ...,  2.5457e+00,\n",
            "           -1.3373e-01, -1.1808e-01],\n",
            "          [ 3.5725e-01, -1.4335e-01,  5.2993e-01,  ..., -2.2515e-01,\n",
            "           -6.6836e-01, -5.5668e-01],\n",
            "          [ 3.3917e-01,  7.3091e-01, -1.4673e-01,  ...,  9.8310e-01,\n",
            "            6.2185e-01, -1.4231e+00],\n",
            "          ...,\n",
            "          [-6.6708e-01, -2.0509e-01, -1.4291e+00,  ...,  6.0633e-01,\n",
            "           -9.3752e-01, -5.9673e-01],\n",
            "          [-3.9225e-01,  1.6264e+00,  1.2001e+00,  ...,  3.4538e-01,\n",
            "           -6.3547e-01, -6.1123e-01],\n",
            "          [ 1.2926e+00,  6.9409e-01,  7.3015e-01,  ..., -1.0618e+00,\n",
            "            1.6678e+00,  3.4159e-01]],\n",
            "\n",
            "         [[-3.0430e-01,  7.8253e-01,  8.7027e-01,  ...,  1.4113e+00,\n",
            "            1.2690e-01, -2.1444e+00],\n",
            "          [ 3.6981e-01,  7.5767e-01,  1.6374e+00,  ..., -1.3816e+00,\n",
            "           -5.0843e-02,  1.1956e+00],\n",
            "          [-7.4226e-01, -6.2396e-01,  2.1230e+00,  ..., -6.6766e-01,\n",
            "           -2.1701e+00, -1.0761e+00],\n",
            "          ...,\n",
            "          [-9.2093e-01, -2.4349e-01,  1.2299e-01,  ..., -2.7193e-01,\n",
            "            7.2503e-01, -1.4547e+00],\n",
            "          [ 9.7146e-03,  2.5922e-01, -9.7454e-01,  ...,  5.3351e-01,\n",
            "            1.6447e-01,  6.0796e-02],\n",
            "          [-4.4190e-01,  1.2595e+00,  9.5390e-01,  ..., -1.8034e-02,\n",
            "           -3.3991e-01, -3.9222e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8272e+00, -9.2275e-01,  4.5273e-01,  ..., -4.0247e-01,\n",
            "            9.5156e-01,  1.2818e-01],\n",
            "          [-3.6888e-01, -1.2150e+00,  2.5502e-01,  ..., -1.4563e+00,\n",
            "            1.7244e-01,  1.1133e+00],\n",
            "          [-9.2036e-01,  1.2191e+00,  9.1860e-01,  ...,  1.6781e+00,\n",
            "           -6.9611e-01, -9.6671e-01],\n",
            "          ...,\n",
            "          [ 5.6893e-01, -8.3848e-01,  5.0986e-01,  ...,  9.6648e-01,\n",
            "            5.3019e-01, -4.4901e-01],\n",
            "          [-1.4157e+00,  7.1190e-01,  2.8090e-01,  ...,  1.9968e-03,\n",
            "            1.0429e-01, -2.3299e+00],\n",
            "          [-6.3801e-01, -1.4864e-01, -3.3225e-01,  ..., -5.8244e-01,\n",
            "           -8.7556e-01,  6.1855e-02]],\n",
            "\n",
            "         [[-1.7039e+00, -7.5949e-01, -1.4446e+00,  ...,  1.4146e+00,\n",
            "           -3.0951e-02,  1.3213e+00],\n",
            "          [-8.8061e-01, -9.2088e-01, -1.2812e+00,  ...,  1.4127e+00,\n",
            "            2.5587e+00, -3.6923e-01],\n",
            "          [-8.8512e-01,  3.7671e-01,  1.2286e+00,  ...,  1.6559e+00,\n",
            "           -1.9456e+00,  1.2278e-01],\n",
            "          ...,\n",
            "          [-1.2472e-01,  1.5508e-02,  4.1202e-02,  ..., -7.2050e-01,\n",
            "            1.2655e+00,  1.5196e-01],\n",
            "          [-8.2075e-01, -5.1662e-02,  2.3718e-01,  ...,  2.7402e-01,\n",
            "            1.2484e-01, -1.9171e+00],\n",
            "          [ 2.0260e-01, -2.0533e-01, -3.1572e-01,  ..., -6.7566e-01,\n",
            "           -5.6582e-01,  5.7799e-02]],\n",
            "\n",
            "         [[-9.7729e-01,  1.3907e+00, -6.0024e-01,  ...,  9.9612e-01,\n",
            "            4.4744e-02,  8.7912e-01],\n",
            "          [ 1.3592e+00, -1.8390e+00,  2.0093e-01,  ...,  2.0759e-01,\n",
            "            4.4135e-01, -3.6272e-01],\n",
            "          [ 2.6012e-02,  5.3701e-01, -2.2195e+00,  ...,  9.8638e-01,\n",
            "            1.7096e+00, -3.7075e-01],\n",
            "          ...,\n",
            "          [ 4.7850e-01,  3.3901e-01,  4.3921e-01,  ...,  1.4843e+00,\n",
            "            1.9405e+00, -2.0761e+00],\n",
            "          [-1.8049e+00,  9.2013e-01, -1.0718e-01,  ...,  1.4830e+00,\n",
            "            1.7915e+00,  2.1438e-01],\n",
            "          [ 8.3022e-01, -7.9408e-01, -1.2001e+00,  ...,  2.5716e-01,\n",
            "           -6.3860e-01,  2.2960e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0286e-01,  4.0985e-01,  1.2151e+00,  ..., -8.5802e-01,\n",
            "            4.4241e-01, -1.1360e+00],\n",
            "          [ 7.9895e-01, -1.0004e+00, -1.5885e-02,  ..., -1.9515e-01,\n",
            "           -1.5862e-01, -1.0723e+00],\n",
            "          [ 4.3573e-01, -5.2513e-01,  1.2712e+00,  ..., -6.1494e-01,\n",
            "           -4.9499e-01,  1.0454e+00],\n",
            "          ...,\n",
            "          [-1.5647e+00, -2.7406e-01,  1.2682e+00,  ...,  3.1373e-02,\n",
            "            4.7036e-01, -1.3232e+00],\n",
            "          [ 2.3755e-01,  7.1788e-01,  9.8803e-01,  ..., -1.1043e+00,\n",
            "            1.1975e+00,  8.2518e-01],\n",
            "          [-1.8383e+00, -7.7924e-01, -1.2467e+00,  ..., -1.2140e-01,\n",
            "            1.7788e+00, -1.1378e+00]],\n",
            "\n",
            "         [[ 1.4521e+00, -1.7661e+00,  5.6722e-01,  ...,  3.3003e-01,\n",
            "            2.4480e-01,  8.0969e-01],\n",
            "          [-3.5976e-02,  1.9738e-01,  1.5713e+00,  ...,  2.4204e+00,\n",
            "           -2.1370e-01,  2.0962e-01],\n",
            "          [-3.1423e-01, -5.0887e-02, -1.7827e+00,  ...,  3.1448e-01,\n",
            "            1.4753e+00, -1.3518e+00],\n",
            "          ...,\n",
            "          [-3.6913e-01, -9.4196e-01, -5.5179e-01,  ...,  5.4699e-01,\n",
            "           -2.7100e-01,  2.3297e-01],\n",
            "          [-1.1883e+00, -8.2917e-01,  2.6549e-01,  ..., -1.1496e+00,\n",
            "            3.7305e-01,  1.5486e+00],\n",
            "          [-4.5205e-01, -4.8901e-01,  1.1461e+00,  ..., -5.2337e-01,\n",
            "            1.3264e+00,  1.4719e+00]],\n",
            "\n",
            "         [[-3.1003e+00, -2.0647e+00, -1.3929e+00,  ..., -6.1282e-01,\n",
            "            8.6374e-01, -3.6633e-01],\n",
            "          [ 2.7331e-01,  7.9132e-01,  2.3672e+00,  ..., -6.0650e-01,\n",
            "            8.7085e-01,  2.0016e-01],\n",
            "          [-1.4009e+00, -5.0746e-02,  1.4321e+00,  ..., -3.5914e-01,\n",
            "            1.3211e-01,  8.3101e-01],\n",
            "          ...,\n",
            "          [-3.0976e-01, -1.0522e+00,  8.0189e-01,  ..., -2.9402e-02,\n",
            "           -1.3322e+00, -7.6636e-01],\n",
            "          [ 5.2366e-01, -5.2819e-01,  1.2382e+00,  ..., -2.6284e-01,\n",
            "            1.0704e+00, -6.2095e-01],\n",
            "          [ 1.2655e-01,  2.3337e-01,  1.4956e+00,  ..., -4.2015e-01,\n",
            "            1.3565e+00,  2.4244e+00]]],\n",
            "\n",
            "\n",
            "        [[[-8.8872e-01, -1.3417e+00,  3.5081e-01,  ..., -6.3930e-01,\n",
            "           -1.2307e-01,  1.6590e-01],\n",
            "          [-3.9604e-01,  3.0567e-01, -1.3041e-01,  ..., -6.3629e-01,\n",
            "            7.3165e-01,  3.5789e-01],\n",
            "          [ 1.2479e-01,  4.8081e-01,  5.1284e-01,  ...,  7.2962e-01,\n",
            "            8.6073e-01,  3.3543e-01],\n",
            "          ...,\n",
            "          [-2.4598e+00,  5.4826e-01, -2.1076e-01,  ..., -1.0709e+00,\n",
            "            6.6607e-01,  1.1959e+00],\n",
            "          [-5.3538e-01, -7.0108e-01,  5.7354e-01,  ...,  1.1883e+00,\n",
            "            5.1121e-01,  8.7195e-02],\n",
            "          [ 2.8342e-01,  1.6221e+00, -4.6148e-01,  ...,  5.9984e-01,\n",
            "           -1.3249e+00,  2.4160e-01]],\n",
            "\n",
            "         [[-6.1685e-02,  3.0355e-01, -1.5984e-01,  ...,  3.0099e-01,\n",
            "            2.4705e-01, -2.6366e+00],\n",
            "          [-2.1553e+00,  2.8899e-01, -1.7207e+00,  ...,  1.5480e+00,\n",
            "            1.0497e+00,  3.3178e-01],\n",
            "          [ 2.3056e-01,  2.2615e-01,  2.2452e+00,  ..., -1.4220e+00,\n",
            "            8.6436e-02, -1.2110e+00],\n",
            "          ...,\n",
            "          [ 1.0476e+00,  1.5243e+00, -2.0926e+00,  ...,  2.2986e-01,\n",
            "            7.8673e-01, -1.0405e+00],\n",
            "          [-5.4392e-01, -5.3415e-01,  6.8633e-01,  ..., -7.6508e-01,\n",
            "            5.2714e-01,  7.8720e-01],\n",
            "          [ 6.3944e-01, -1.2904e+00,  5.1935e-01,  ..., -1.1112e-01,\n",
            "            2.0258e+00, -1.7549e+00]],\n",
            "\n",
            "         [[-5.9444e-01,  2.4041e-01,  1.3227e+00,  ...,  4.9738e-01,\n",
            "            1.5384e+00, -9.8763e-01],\n",
            "          [ 1.4615e-01,  8.7233e-02, -2.1696e+00,  ...,  6.1413e-01,\n",
            "            7.2987e-02,  5.2822e-01],\n",
            "          [-1.8983e+00,  4.7145e-01,  3.0205e-01,  ...,  1.9280e+00,\n",
            "           -1.8364e-01, -1.3957e+00],\n",
            "          ...,\n",
            "          [ 1.6588e+00, -1.8770e+00, -1.3359e+00,  ..., -7.5169e-01,\n",
            "            5.3210e-01,  7.6558e-01],\n",
            "          [-1.1667e+00,  9.1507e-03,  2.0501e-01,  ...,  1.0713e+00,\n",
            "            4.4475e-01, -2.2616e+00],\n",
            "          [-5.1136e-01,  2.7860e-01,  1.3511e+00,  ...,  1.3759e+00,\n",
            "            5.1099e-01, -1.3134e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0683e+00,  8.3526e-01,  3.2532e-01,  ...,  6.3285e-01,\n",
            "           -1.0663e+00, -6.9432e-01],\n",
            "          [ 2.0805e+00,  1.0472e+00, -4.0751e-01,  ..., -2.4772e+00,\n",
            "           -3.4303e-01, -1.3118e+00],\n",
            "          [-4.2967e-01, -1.4471e+00,  2.1670e+00,  ...,  2.9987e-01,\n",
            "            1.5245e+00, -6.3296e-01],\n",
            "          ...,\n",
            "          [ 1.1272e-01,  5.9602e-01,  8.1579e-01,  ...,  4.9444e-01,\n",
            "            3.1294e-01, -1.1040e+00],\n",
            "          [-7.9606e-01, -6.0143e-01, -1.8306e-01,  ..., -4.9453e-01,\n",
            "            6.9705e-01, -1.1946e+00],\n",
            "          [-9.5782e-01,  9.0530e-01, -1.2178e+00,  ..., -5.9686e-01,\n",
            "           -1.1053e+00,  2.2029e+00]],\n",
            "\n",
            "         [[-5.2035e-01, -5.1076e-01, -1.1133e+00,  ...,  2.0859e+00,\n",
            "           -1.3174e+00,  5.7967e-01],\n",
            "          [ 1.0141e+00,  1.5779e+00,  5.9473e-01,  ...,  3.7301e-01,\n",
            "           -1.0962e+00, -3.1206e-02],\n",
            "          [-1.7528e+00,  4.2541e-01,  1.4198e-01,  ..., -2.3508e-02,\n",
            "           -1.1168e+00, -3.1316e+00],\n",
            "          ...,\n",
            "          [-3.9546e-03, -1.8467e+00,  7.9554e-01,  ..., -1.8872e-01,\n",
            "           -2.6162e-02,  2.7826e-01],\n",
            "          [ 1.4046e+00,  5.2693e-01, -1.3650e+00,  ..., -1.7094e+00,\n",
            "            6.4436e-01,  1.2411e+00],\n",
            "          [ 6.8320e-02,  1.1819e+00, -4.4959e-01,  ...,  1.4828e-01,\n",
            "            1.2088e+00,  9.5070e-01]],\n",
            "\n",
            "         [[-8.0670e-02, -7.8014e-01,  3.0895e-01,  ...,  1.0699e+00,\n",
            "           -1.4829e+00, -7.2191e-01],\n",
            "          [ 8.5369e-01,  9.3453e-01, -1.0875e+00,  ...,  1.8657e+00,\n",
            "            3.7281e-01,  4.9862e-01],\n",
            "          [ 7.8827e-01, -1.1872e+00, -9.7449e-01,  ..., -1.6302e+00,\n",
            "           -7.0565e-01, -2.9756e-02],\n",
            "          ...,\n",
            "          [-6.8055e-01, -5.1808e-01, -2.1535e-02,  ...,  8.1474e-01,\n",
            "            3.7182e-01,  2.2346e-01],\n",
            "          [ 1.6513e+00, -4.6039e-01,  8.7765e-01,  ...,  6.1503e-01,\n",
            "           -1.3858e-01,  5.3739e-01],\n",
            "          [ 7.7500e-01, -1.0206e+00, -7.4144e-01,  ..., -1.4620e+00,\n",
            "            6.4861e-01,  7.6046e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8501e+00, -9.0594e-01,  4.4665e-02,  ...,  9.2707e-01,\n",
            "            1.2871e+00, -1.3658e+00],\n",
            "          [-8.3960e-01,  1.5600e+00, -9.3727e-01,  ...,  4.2373e-01,\n",
            "            6.7243e-01, -3.6405e-02],\n",
            "          [ 3.7617e-01, -1.0748e+00,  2.1289e-02,  ..., -7.7334e-01,\n",
            "           -8.1912e-01,  4.7381e-01],\n",
            "          ...,\n",
            "          [ 5.6495e-01, -2.7670e-01,  5.0052e-01,  ..., -8.0451e-01,\n",
            "            9.9183e-01,  5.4743e-01],\n",
            "          [ 1.9337e+00,  1.6202e-01, -1.9380e-02,  ...,  7.9581e-01,\n",
            "           -2.1949e-02, -1.9781e-01],\n",
            "          [ 3.6471e-01,  1.1783e+00,  1.1380e+00,  ..., -1.2107e+00,\n",
            "            6.4544e-01, -1.5041e+00]],\n",
            "\n",
            "         [[ 1.8068e+00, -2.8109e-01,  5.6407e-01,  ...,  4.8604e-01,\n",
            "            1.1035e+00,  5.3144e-01],\n",
            "          [ 1.9426e+00,  2.6099e+00, -1.4269e-01,  ..., -1.9477e+00,\n",
            "            8.9918e-01,  3.6973e-01],\n",
            "          [ 8.9910e-02, -1.3363e-01, -1.2129e+00,  ..., -1.2382e+00,\n",
            "           -9.8950e-01,  6.4546e-01],\n",
            "          ...,\n",
            "          [-1.8106e+00,  1.9508e-01, -4.3765e-01,  ..., -1.8277e-01,\n",
            "            1.9504e+00,  1.2249e+00],\n",
            "          [-1.5644e-01,  1.3043e-01,  1.6524e+00,  ..., -8.0727e-01,\n",
            "           -2.9966e-01,  1.1373e+00],\n",
            "          [ 1.0492e+00, -1.4408e+00,  1.1525e+00,  ..., -2.8377e-01,\n",
            "           -4.7875e-01,  6.3663e-01]],\n",
            "\n",
            "         [[-2.2483e-01,  1.1435e+00,  2.0595e+00,  ...,  3.8783e-01,\n",
            "           -1.0243e+00, -1.6211e+00],\n",
            "          [ 6.6322e-01,  4.0068e-01,  1.1281e+00,  ...,  6.1773e-01,\n",
            "           -8.6329e-01,  8.2730e-01],\n",
            "          [-3.2326e-02, -7.5417e-01, -1.2003e+00,  ..., -2.5642e+00,\n",
            "           -1.0346e+00, -3.7636e-01],\n",
            "          ...,\n",
            "          [-1.5355e-02,  1.7470e-01, -3.1951e-01,  ..., -1.6472e+00,\n",
            "            1.3578e+00,  8.8148e-01],\n",
            "          [ 1.3558e+00, -5.9136e-01, -1.8725e-01,  ...,  1.1224e+00,\n",
            "            1.2133e-01,  1.4078e+00],\n",
            "          [ 8.2744e-01,  5.1692e-01, -3.1351e-01,  ...,  6.0890e-01,\n",
            "           -2.6902e-01, -2.3603e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1285e-01,  2.9798e-01, -7.5596e-01,  ...,  9.2672e-01,\n",
            "            2.8182e-01, -7.1654e-01],\n",
            "          [-2.9131e-01, -4.9152e-01,  1.6927e+00,  ..., -1.1442e-01,\n",
            "           -1.3082e+00,  3.6314e-01],\n",
            "          [ 1.5298e+00,  8.0906e-01, -7.1998e-01,  ...,  1.9363e+00,\n",
            "           -1.1328e+00,  1.5634e+00],\n",
            "          ...,\n",
            "          [-7.6539e-01, -8.5822e-02, -6.1149e-01,  ..., -5.1945e-01,\n",
            "           -1.3105e-01,  2.2579e-01],\n",
            "          [ 8.7687e-03, -8.8920e-01, -8.5755e-01,  ..., -1.0341e+00,\n",
            "            2.9059e-01, -1.6580e+00],\n",
            "          [-1.6443e+00,  7.0262e-01, -1.0647e+00,  ...,  5.5791e-02,\n",
            "           -1.3287e+00, -6.4905e-01]],\n",
            "\n",
            "         [[ 6.8590e-01, -1.6421e+00,  5.0557e-01,  ..., -1.3698e+00,\n",
            "            1.4055e+00,  2.3337e-03],\n",
            "          [-2.6855e-01,  6.3232e-01,  5.4759e-01,  ..., -1.2521e+00,\n",
            "            2.0978e-01,  1.2100e+00],\n",
            "          [-1.2426e+00, -1.2862e-03, -2.4014e-01,  ...,  2.1463e+00,\n",
            "            1.3532e+00, -7.8567e-01],\n",
            "          ...,\n",
            "          [-3.7380e-01,  1.0154e+00, -1.2806e+00,  ...,  1.3443e-01,\n",
            "            3.3663e-01,  1.3523e+00],\n",
            "          [-1.1101e-01, -1.3254e-01, -2.4682e-01,  ...,  3.2592e-01,\n",
            "           -2.8524e-01, -1.3705e+00],\n",
            "          [ 5.8077e-01, -1.2369e+00, -1.5835e-01,  ..., -1.8937e+00,\n",
            "            1.4834e+00,  1.7017e+00]],\n",
            "\n",
            "         [[ 7.0577e-02,  4.2881e-01,  1.0247e-01,  ..., -3.3940e-01,\n",
            "           -5.9415e-02, -9.8065e-01],\n",
            "          [ 6.7544e-01,  4.3115e-01, -3.2111e-01,  ..., -1.0820e+00,\n",
            "           -1.2053e+00,  2.6910e-01],\n",
            "          [ 1.3996e+00, -5.0607e-01,  1.8811e+00,  ..., -2.3285e-01,\n",
            "           -5.4930e-01,  4.0142e-01],\n",
            "          ...,\n",
            "          [-2.2802e+00,  4.3633e-01,  6.4036e-02,  ...,  2.1319e+00,\n",
            "           -3.2227e-01, -4.0695e-01],\n",
            "          [-4.9966e-01,  1.3135e-01,  9.4313e-01,  ..., -4.0490e-01,\n",
            "            1.4711e+00, -1.6768e+00],\n",
            "          [ 9.7592e-02, -5.5169e-01, -1.4920e-03,  ..., -1.0410e-01,\n",
            "            4.3878e-01, -2.4162e+00]]]])\n",
            "tensor([[[[ 6.6345e-02,  3.1488e-01,  7.2291e-03,  ..., -4.1805e-01,\n",
            "            9.5746e-02, -3.0748e-01],\n",
            "          [ 2.3524e-01,  8.0720e-01, -1.1959e-01,  ..., -4.0800e-03,\n",
            "            1.3988e-01, -8.7956e-02],\n",
            "          [ 3.6258e-01,  5.4377e-01,  1.1528e+00,  ...,  6.6361e-01,\n",
            "           -2.8251e-01,  4.2066e-01],\n",
            "          ...,\n",
            "          [ 2.6893e-01,  8.0275e-01,  5.0595e-01,  ...,  8.0660e-01,\n",
            "           -1.0610e-01,  7.0390e-01],\n",
            "          [-2.7997e-01, -1.0010e+00, -4.1761e-01,  ...,  5.5083e-01,\n",
            "           -2.9264e-01,  4.6551e-01],\n",
            "          [-1.2788e-01, -3.6559e-01, -4.7079e-01,  ...,  1.0210e+00,\n",
            "            2.3318e-01, -1.9269e-01]],\n",
            "\n",
            "         [[-1.6400e-01,  3.0836e-01,  1.1247e-01,  ..., -3.3614e-01,\n",
            "           -5.6580e-01, -1.5614e-01],\n",
            "          [ 2.4834e-01,  6.3212e-01,  2.3778e-01,  ..., -1.8950e-01,\n",
            "            2.6994e-02,  3.7445e-01],\n",
            "          [ 6.5585e-01,  6.5095e-01,  1.3704e-01,  ...,  8.9217e-01,\n",
            "            3.2989e-01,  1.6584e-02],\n",
            "          ...,\n",
            "          [-6.2096e-01, -7.3112e-02,  3.8658e-02,  ...,  8.4275e-02,\n",
            "           -5.6719e-01,  2.8456e-01],\n",
            "          [ 4.4683e-01,  2.1936e-01, -5.1391e-01,  ...,  3.7972e-01,\n",
            "            6.8957e-01,  3.6118e-01],\n",
            "          [ 6.0109e-01,  2.3171e-01,  4.1033e-01,  ..., -1.8935e-01,\n",
            "            5.7422e-01,  5.5928e-01]],\n",
            "\n",
            "         [[ 8.5005e-02,  2.0361e-01, -3.1122e-01,  ..., -1.1543e-01,\n",
            "            6.3038e-02, -9.9224e-02],\n",
            "          [ 2.5333e-01, -5.8558e-02,  7.3642e-01,  ...,  3.0794e-01,\n",
            "           -4.4834e-01, -5.6963e-02],\n",
            "          [ 8.3447e-02,  9.7481e-02, -5.6058e-02,  ..., -3.9578e-02,\n",
            "           -4.6668e-01,  4.6660e-02],\n",
            "          ...,\n",
            "          [ 4.6368e-01, -6.1423e-01, -3.1572e-01,  ...,  3.6176e-01,\n",
            "            9.8960e-01, -8.9506e-02],\n",
            "          [-6.8050e-01, -3.0664e-01,  3.6657e-01,  ..., -2.4087e-01,\n",
            "            9.0001e-01,  8.4497e-02],\n",
            "          [-4.6672e-01, -1.4573e-01,  3.0617e-01,  ...,  8.2245e-02,\n",
            "           -1.9305e-01, -7.5347e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4633e-01, -6.0476e-02,  2.1700e-02,  ...,  1.1499e-01,\n",
            "           -3.5798e-01, -2.1261e-01],\n",
            "          [-4.3029e-01, -2.7361e-02,  3.8284e-01,  ..., -4.1370e-01,\n",
            "            1.2449e-01, -2.4726e-03],\n",
            "          [ 1.9343e-01, -3.0734e-01,  2.3786e-02,  ..., -4.8288e-01,\n",
            "           -6.9408e-02, -4.9044e-01],\n",
            "          ...,\n",
            "          [-7.7066e-02, -2.5886e-01,  2.6610e-01,  ..., -1.6241e-01,\n",
            "            1.6836e-01, -8.9047e-01],\n",
            "          [-3.8129e-01, -4.4655e-01, -3.4466e-01,  ..., -1.2721e-01,\n",
            "           -2.9582e-01, -5.1931e-01],\n",
            "          [ 3.6198e-01, -4.4524e-01,  1.8963e-02,  ...,  1.1704e-02,\n",
            "           -2.5250e-01, -3.4190e-01]],\n",
            "\n",
            "         [[ 3.0583e-01, -5.8954e-01, -7.7167e-02,  ..., -1.0275e-01,\n",
            "            2.2220e-01,  4.6339e-01],\n",
            "          [-2.5815e-02,  4.2548e-02, -1.3434e-01,  ..., -3.8190e-01,\n",
            "           -6.4625e-01, -7.8812e-01],\n",
            "          [ 6.1681e-01, -9.6497e-02, -3.5739e-01,  ..., -9.7392e-01,\n",
            "            2.8848e-01, -5.3554e-01],\n",
            "          ...,\n",
            "          [ 4.2609e-02,  6.2553e-01, -1.1525e-01,  ...,  7.6363e-01,\n",
            "           -5.5313e-01,  6.1345e-01],\n",
            "          [-1.0096e-01, -3.3472e-01, -2.4348e-01,  ...,  1.0771e+00,\n",
            "           -1.6160e-01,  6.8731e-02],\n",
            "          [ 1.2084e-01, -5.7316e-01, -8.2066e-01,  ...,  5.0027e-01,\n",
            "            1.3657e-01, -2.6585e-01]],\n",
            "\n",
            "         [[-3.6477e-01,  1.8228e-01, -1.7363e-01,  ...,  3.7355e-01,\n",
            "           -1.7767e-01, -3.8494e-01],\n",
            "          [-3.3543e-01,  5.1470e-02, -1.6368e-01,  ...,  2.0004e-01,\n",
            "           -2.8962e-01, -5.1891e-01],\n",
            "          [ 1.1746e-01, -9.0222e-01,  3.7032e-01,  ...,  2.7115e-02,\n",
            "            8.6766e-01,  3.2929e-02],\n",
            "          ...,\n",
            "          [-4.0943e-01, -1.5960e-01, -2.8278e-01,  ..., -3.8543e-01,\n",
            "            1.1381e-02,  1.8578e-01],\n",
            "          [ 1.5967e-01, -1.2537e-01,  2.8819e-01,  ...,  6.9347e-01,\n",
            "            7.5201e-01, -1.5063e-01],\n",
            "          [ 4.9132e-02,  7.4145e-01,  5.2392e-01,  ..., -9.8441e-01,\n",
            "           -2.1121e-01,  3.8663e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8446e-01,  1.2480e-01, -2.1825e-01,  ..., -4.6570e-01,\n",
            "            1.3720e-01,  4.2578e-02],\n",
            "          [-2.9508e-01, -4.9052e-01, -8.4573e-01,  ..., -3.3045e-01,\n",
            "            3.1709e-01,  5.8103e-01],\n",
            "          [-1.8274e-01,  1.6970e-01, -3.9824e-01,  ..., -2.3370e-01,\n",
            "           -1.1626e-01, -9.9950e-02],\n",
            "          ...,\n",
            "          [-5.7913e-01,  1.8923e-02,  2.7756e-02,  ...,  7.0696e-01,\n",
            "            5.3966e-01,  5.4361e-01],\n",
            "          [ 4.4727e-01, -6.5257e-01,  8.9060e-01,  ..., -2.1856e-02,\n",
            "           -1.9693e-01, -3.6984e-01],\n",
            "          [-2.5101e-02,  6.3101e-01, -1.1014e-01,  ..., -4.1811e-01,\n",
            "           -2.1261e-01,  6.2446e-01]],\n",
            "\n",
            "         [[-2.3707e-01,  1.2279e-01,  1.0190e-01,  ...,  4.3569e-02,\n",
            "            1.1529e-02,  1.0330e-02],\n",
            "          [ 3.6340e-01,  5.2212e-01,  9.7401e-01,  ..., -4.0628e-02,\n",
            "            2.9058e-02,  9.4070e-01],\n",
            "          [ 3.3217e-01,  3.4801e-01,  2.0167e-01,  ...,  1.2775e-01,\n",
            "            2.3094e-01,  1.8693e-01],\n",
            "          ...,\n",
            "          [-1.5659e-01, -7.2373e-02,  2.2866e-01,  ..., -3.8791e-01,\n",
            "            2.5521e-01,  7.7943e-02],\n",
            "          [-3.8559e-02,  2.0735e-01, -1.1667e+00,  ..., -1.5633e-01,\n",
            "            2.9367e-01,  3.3149e-01],\n",
            "          [-4.9016e-01, -1.5292e-02,  1.1433e-01,  ..., -1.1107e+00,\n",
            "           -5.3990e-01,  4.6239e-02]],\n",
            "\n",
            "         [[-7.7603e-01,  1.8706e-01,  3.9574e-01,  ...,  2.0573e-01,\n",
            "           -2.5294e-01, -2.7083e-01],\n",
            "          [ 1.2930e-01, -2.1454e-01,  1.0219e-01,  ...,  1.0975e-01,\n",
            "            3.3908e-02, -6.6090e-01],\n",
            "          [ 4.1043e-01,  1.6898e-01,  4.8864e-01,  ...,  1.1940e-02,\n",
            "            8.7340e-02, -6.7974e-01],\n",
            "          ...,\n",
            "          [-8.4606e-01,  3.3820e-01, -1.7491e-01,  ...,  1.0767e+00,\n",
            "            6.7756e-02,  5.4277e-02],\n",
            "          [-6.7840e-01, -9.5356e-01,  5.9350e-01,  ..., -3.8468e-01,\n",
            "           -1.1350e+00, -4.9945e-01],\n",
            "          [ 2.0387e-01,  8.4644e-01, -3.3648e-02,  ...,  3.3567e-01,\n",
            "           -3.9617e-01,  2.2431e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.0646e-01,  5.3748e-03, -7.5013e-01,  ...,  1.0081e-02,\n",
            "            1.7512e-01, -2.2997e-01],\n",
            "          [-8.6399e-02, -2.4185e-01, -5.6356e-01,  ...,  4.8289e-01,\n",
            "            4.0404e-02,  4.8670e-01],\n",
            "          [-6.7019e-02, -2.2011e-01,  1.6119e-01,  ...,  6.2133e-01,\n",
            "           -7.5555e-01, -2.3684e-01],\n",
            "          ...,\n",
            "          [-3.8288e-01,  9.6178e-02,  2.3182e-01,  ...,  6.9862e-01,\n",
            "           -4.3968e-01,  3.2426e-01],\n",
            "          [ 4.9967e-01,  6.0608e-01, -1.0192e+00,  ..., -2.9330e-01,\n",
            "            6.9589e-01,  6.8337e-01],\n",
            "          [ 3.7643e-01,  9.7254e-02,  1.7920e-02,  ...,  3.8436e-01,\n",
            "           -3.9591e-02,  2.0783e-01]],\n",
            "\n",
            "         [[ 1.3870e-01,  1.7011e-01,  2.2488e-01,  ..., -4.5237e-01,\n",
            "            2.2282e-01,  1.0626e-01],\n",
            "          [ 3.9488e-01,  7.8221e-02, -7.4793e-01,  ...,  3.1929e-01,\n",
            "            2.1639e-01, -6.0553e-02],\n",
            "          [-2.9180e-01, -1.4317e-01, -2.8202e-01,  ...,  2.5888e-01,\n",
            "            1.7071e-01,  6.0600e-01],\n",
            "          ...,\n",
            "          [ 3.0553e-01, -1.0001e+00,  5.7397e-01,  ..., -7.5197e-01,\n",
            "           -5.9476e-01, -2.1928e-01],\n",
            "          [ 2.3008e-01,  6.8437e-02,  9.4326e-01,  ...,  4.9434e-01,\n",
            "            1.9105e-01,  2.1536e-01],\n",
            "          [-1.3048e-01,  9.4192e-01,  3.0472e-01,  ..., -3.8292e-01,\n",
            "            2.7001e-01, -3.0000e-01]],\n",
            "\n",
            "         [[-2.7265e-01, -9.8575e-02, -3.1808e-01,  ...,  2.2665e-01,\n",
            "            3.0444e-01,  3.4179e-01],\n",
            "          [ 4.3583e-01,  4.7193e-02,  4.1962e-01,  ..., -2.8219e-01,\n",
            "           -1.0479e-01,  2.2726e-01],\n",
            "          [ 4.4704e-02,  2.6743e-01, -8.0877e-01,  ..., -3.5464e-01,\n",
            "            1.1797e-01, -1.7446e-01],\n",
            "          ...,\n",
            "          [-9.5097e-01,  7.8327e-01,  3.6399e-01,  ...,  1.3921e+00,\n",
            "            1.4916e-02, -7.2068e-01],\n",
            "          [-1.5783e-01, -1.4521e-01,  9.2028e-02,  ...,  8.9183e-02,\n",
            "            7.6094e-01,  5.8847e-01],\n",
            "          [-3.1180e-01, -4.4344e-01, -1.1454e+00,  ...,  7.9732e-01,\n",
            "            6.8826e-01, -2.0113e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.3148e-02, -2.2745e-01, -2.4623e-04,  ...,  2.6612e-01,\n",
            "            9.4753e-01,  6.4451e-02],\n",
            "          [ 1.0119e-01,  3.4283e-03,  1.1130e-01,  ...,  3.9467e-01,\n",
            "            1.4577e-01, -3.1191e-01],\n",
            "          [-6.4447e-01,  1.9277e-01, -4.1684e-01,  ..., -1.3266e+00,\n",
            "           -8.3594e-01, -3.7476e-01],\n",
            "          ...,\n",
            "          [ 4.3303e-01, -3.4087e-01, -7.6639e-01,  ...,  2.6938e-01,\n",
            "            6.1387e-01,  3.0566e-01],\n",
            "          [ 1.8779e-01,  4.3412e-01,  4.7607e-01,  ..., -5.3255e-01,\n",
            "            4.1235e-01, -3.4128e-02],\n",
            "          [ 1.3862e-01,  3.3545e-01,  5.1789e-01,  ..., -1.7305e-01,\n",
            "           -4.0455e-01,  3.3587e-01]],\n",
            "\n",
            "         [[ 1.7055e-01, -2.7532e-01, -3.1698e-01,  ...,  5.0162e-01,\n",
            "            8.0466e-01,  2.6441e-01],\n",
            "          [-2.7284e-01,  8.9749e-01, -8.4119e-02,  ..., -3.1694e-01,\n",
            "           -3.9763e-01, -3.9027e-01],\n",
            "          [-1.8611e-01, -2.6049e-01, -3.6645e-01,  ..., -3.1839e-01,\n",
            "           -7.0076e-01,  1.7360e-01],\n",
            "          ...,\n",
            "          [ 6.1293e-03,  1.0451e-01, -5.3399e-01,  ..., -1.2741e-01,\n",
            "            4.0142e-01, -1.9626e-01],\n",
            "          [-1.2059e-03,  8.2503e-01, -5.5463e-01,  ..., -8.8484e-03,\n",
            "            2.0129e-01, -5.9565e-01],\n",
            "          [-1.7717e-01,  1.5709e-01,  6.5765e-01,  ...,  1.1029e-01,\n",
            "           -3.3885e-01,  2.0993e-01]],\n",
            "\n",
            "         [[ 1.7568e-01, -8.1973e-01, -2.4516e-01,  ...,  4.4615e-02,\n",
            "           -4.0171e-01,  1.0894e-01],\n",
            "          [-1.5040e-01, -1.0464e-01, -3.4922e-01,  ..., -6.4874e-01,\n",
            "            4.2249e-01,  1.0636e-01],\n",
            "          [ 2.2591e-01,  1.6099e-01,  4.7957e-01,  ..., -1.3282e+00,\n",
            "            5.7943e-02, -1.5536e-01],\n",
            "          ...,\n",
            "          [ 2.4847e-01, -1.3243e-01, -4.5225e-01,  ..., -2.4263e-01,\n",
            "            4.0074e-01,  7.8546e-01],\n",
            "          [ 8.3478e-02, -4.5482e-01, -1.7874e-01,  ...,  9.3727e-01,\n",
            "            8.9037e-02,  6.4100e-01],\n",
            "          [-9.7324e-02,  6.9464e-02,  1.1822e-01,  ...,  1.7855e-01,\n",
            "            6.4993e-01,  3.5972e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0488e-01, -4.6514e-01, -1.5165e-02,  ...,  5.0349e-02,\n",
            "            1.2609e-02, -5.6517e-03],\n",
            "          [ 5.8821e-01, -4.3741e-01,  4.0388e-01,  ..., -2.6536e-01,\n",
            "            3.4860e-01,  4.2923e-01],\n",
            "          [ 2.6442e-01,  6.1104e-01, -6.6239e-01,  ..., -4.2340e-01,\n",
            "            2.2703e-01, -4.1119e-01],\n",
            "          ...,\n",
            "          [-4.2010e-02, -1.8466e-01,  4.0779e-01,  ...,  1.0804e+00,\n",
            "           -3.9528e-01,  2.8386e-01],\n",
            "          [ 2.8486e-01, -9.6260e-01,  3.4641e-01,  ..., -5.4189e-02,\n",
            "           -2.3785e-01, -2.0393e-01],\n",
            "          [-3.3168e-01, -5.5266e-01,  2.9238e-01,  ...,  3.0866e-01,\n",
            "            1.0545e+00,  1.1725e-01]],\n",
            "\n",
            "         [[-1.2112e-01, -1.3931e-01, -5.1135e-02,  ..., -1.9405e-01,\n",
            "           -1.6941e-01, -3.4396e-01],\n",
            "          [ 2.7147e-01, -3.0483e-01,  1.6445e-02,  ...,  2.9156e-01,\n",
            "           -7.3153e-02,  2.4757e-01],\n",
            "          [-2.9816e-01,  3.9245e-01, -1.5679e-01,  ..., -9.7232e-01,\n",
            "            3.1068e-01, -3.2910e-01],\n",
            "          ...,\n",
            "          [-7.2128e-01,  7.7063e-01,  1.1837e-01,  ...,  1.0759e+00,\n",
            "            2.0809e-01,  1.4459e-01],\n",
            "          [-4.0889e-01, -1.9861e-01, -7.5971e-01,  ..., -2.5854e-01,\n",
            "           -2.5339e-01, -1.9313e-01],\n",
            "          [ 5.7060e-02,  6.2236e-01,  2.9012e-01,  ...,  3.5635e-01,\n",
            "            5.3515e-01, -2.7357e-01]],\n",
            "\n",
            "         [[ 2.4607e-02,  2.7069e-01,  2.5068e-01,  ..., -2.9745e-01,\n",
            "            6.1998e-01,  2.6595e-01],\n",
            "          [-9.3170e-01,  3.0736e-01,  4.4643e-01,  ..., -2.0159e-01,\n",
            "           -4.2486e-02,  2.3161e-02],\n",
            "          [-2.0501e-02, -5.0114e-01, -3.6845e-01,  ...,  1.0410e+00,\n",
            "           -7.5666e-02,  2.7761e-01],\n",
            "          ...,\n",
            "          [ 1.1253e+00, -1.9991e-01,  5.3577e-01,  ...,  1.2077e-01,\n",
            "            1.8873e-01,  1.7372e-01],\n",
            "          [ 2.7384e-01,  8.0401e-01,  7.7047e-01,  ...,  1.0559e-01,\n",
            "           -1.3226e-01, -2.6561e-01],\n",
            "          [-8.7277e-02, -4.7011e-02,  2.9481e-01,  ...,  1.8544e-01,\n",
            "           -8.9366e-03,  2.2846e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.4564e-01,  8.4992e-02, -1.2034e-01,  ...,  5.7952e-02,\n",
            "            1.8116e-01, -2.4168e-01],\n",
            "          [-1.8288e-01,  4.2834e-01,  4.9234e-01,  ..., -4.1783e-01,\n",
            "            7.4485e-01, -8.3006e-02],\n",
            "          [ 4.3298e-01, -8.7847e-01, -4.3244e-01,  ...,  6.5996e-01,\n",
            "            4.2045e-01,  3.2278e-01],\n",
            "          ...,\n",
            "          [ 1.0149e+00,  7.2282e-01,  3.6905e-01,  ..., -2.7902e-01,\n",
            "           -1.3890e+00,  9.2748e-01],\n",
            "          [ 9.8050e-02, -2.7760e-01, -8.6363e-01,  ...,  4.1173e-01,\n",
            "           -6.7470e-01, -6.0536e-01],\n",
            "          [-2.2824e-01, -5.1201e-01, -1.4736e+00,  ..., -9.6926e-02,\n",
            "            1.0536e+00,  3.7540e-01]],\n",
            "\n",
            "         [[ 1.6311e-01,  2.6323e-01,  3.3810e-01,  ..., -3.8064e-01,\n",
            "            5.1000e-02,  3.3510e-02],\n",
            "          [-8.0511e-02, -8.3027e-02,  1.0690e+00,  ...,  7.1465e-02,\n",
            "            1.1930e-01, -5.8254e-01],\n",
            "          [-6.6519e-01,  7.6308e-02,  8.9856e-02,  ...,  1.9480e-01,\n",
            "            5.3059e-01,  1.2185e-01],\n",
            "          ...,\n",
            "          [ 4.1959e-01, -1.3951e-02, -2.8263e-01,  ...,  7.3869e-01,\n",
            "           -2.1369e-01,  2.6973e-01],\n",
            "          [-2.1449e-01,  4.5016e-01, -7.6701e-02,  ...,  1.3201e-02,\n",
            "            2.7886e-01, -7.2171e-01],\n",
            "          [-7.4116e-02,  4.7312e-01,  2.1727e-01,  ...,  1.9506e-01,\n",
            "           -2.6294e-02,  6.2511e-01]],\n",
            "\n",
            "         [[-3.5609e-01, -2.8639e-01, -6.2257e-02,  ...,  4.2534e-01,\n",
            "           -1.3050e-01, -3.0774e-01],\n",
            "          [ 9.7110e-02, -5.1516e-01,  8.6480e-02,  ..., -8.3366e-01,\n",
            "            7.0056e-01,  8.1019e-02],\n",
            "          [ 2.2896e-02, -1.7717e-01, -5.3016e-01,  ..., -9.3913e-01,\n",
            "           -4.8124e-01, -7.5725e-02],\n",
            "          ...,\n",
            "          [-8.7082e-01,  7.9928e-01, -1.1574e-01,  ..., -1.9778e-01,\n",
            "            2.0953e-01, -1.0367e-01],\n",
            "          [-2.2006e-01, -1.4057e-01, -2.7742e-01,  ...,  3.7592e-01,\n",
            "           -7.7124e-01, -9.6013e-02],\n",
            "          [-6.9242e-01, -9.2257e-01, -1.1657e-01,  ...,  1.6573e-01,\n",
            "           -3.5460e-01, -2.3844e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9005e-01, -2.0445e-01,  6.7860e-01,  ...,  6.6712e-02,\n",
            "           -2.3671e-01,  4.6424e-01],\n",
            "          [-1.4068e-02,  2.7544e-01, -6.5867e-01,  ..., -8.8799e-01,\n",
            "            1.3903e-01, -1.4523e-01],\n",
            "          [-8.1836e-02, -1.4549e-01,  1.4072e-01,  ..., -5.1332e-01,\n",
            "           -8.9259e-01,  1.2981e-01],\n",
            "          ...,\n",
            "          [-8.0804e-01,  1.5507e-01,  2.1760e-01,  ..., -5.5072e-01,\n",
            "           -8.4286e-01, -6.6198e-01],\n",
            "          [-3.1944e-02, -3.3076e-01, -1.5654e-01,  ..., -3.1924e-01,\n",
            "            5.9402e-01, -6.2076e-02],\n",
            "          [-4.9888e-01,  3.3914e-01,  1.7259e-03,  ...,  3.2663e-01,\n",
            "           -1.2577e-01, -9.8040e-01]],\n",
            "\n",
            "         [[-2.0842e-02,  8.6067e-02, -1.0570e-01,  ...,  3.1107e-01,\n",
            "            1.5758e-01,  1.8041e-01],\n",
            "          [ 6.2031e-01, -7.8049e-02, -6.9730e-01,  ..., -1.1079e+00,\n",
            "           -7.6200e-02,  6.0494e-01],\n",
            "          [-4.8076e-01,  1.2327e+00,  1.4648e+00,  ...,  2.1777e-01,\n",
            "            2.0467e-01, -8.8277e-02],\n",
            "          ...,\n",
            "          [-9.6377e-02, -6.2680e-01,  4.9786e-01,  ...,  4.6494e-02,\n",
            "            9.8362e-03,  1.4221e-01],\n",
            "          [-2.6693e-01, -1.7710e-01,  1.7348e-01,  ...,  8.6097e-01,\n",
            "           -6.2744e-01, -2.8976e-02],\n",
            "          [-3.4800e-02,  2.5183e-01,  5.8048e-01,  ...,  3.8741e-02,\n",
            "            9.7035e-03,  1.9499e-01]],\n",
            "\n",
            "         [[-3.2523e-01, -6.6815e-02,  4.0589e-02,  ...,  1.6885e-01,\n",
            "           -2.6227e-01,  1.6836e-01],\n",
            "          [-2.7997e-01, -4.6614e-01, -1.5256e-01,  ...,  3.4474e-01,\n",
            "            2.1850e-01, -4.3410e-01],\n",
            "          [-6.6830e-01, -8.7709e-01, -9.2917e-02,  ...,  3.5474e-01,\n",
            "            2.8508e-01, -3.1235e-03],\n",
            "          ...,\n",
            "          [-2.1343e-01,  5.7153e-01, -9.0768e-01,  ...,  1.0639e+00,\n",
            "            6.3234e-01,  5.9891e-01],\n",
            "          [-2.5495e-01,  6.7133e-01,  8.5204e-01,  ...,  9.1860e-03,\n",
            "            7.4772e-01,  1.7392e-01],\n",
            "          [ 3.9230e-01,  3.5659e-01, -7.2661e-01,  ..., -5.6752e-01,\n",
            "           -1.9793e-01,  5.9870e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8311e-02,  1.7520e-01,  5.3399e-02,  ...,  3.7635e-01,\n",
            "            2.8037e-02, -7.0146e-02],\n",
            "          [ 2.1621e-01, -1.7902e-02, -1.8095e-01,  ...,  4.9640e-01,\n",
            "            7.2697e-01,  9.8824e-03],\n",
            "          [ 1.4149e-01,  8.8923e-02, -4.4209e-01,  ..., -1.2961e-01,\n",
            "            1.2492e+00,  2.0674e-01],\n",
            "          ...,\n",
            "          [ 4.2944e-02,  1.5491e-01,  2.1029e-01,  ..., -1.3774e+00,\n",
            "            2.7480e-01, -9.9384e-02],\n",
            "          [ 1.8785e-01,  5.3697e-01, -3.5284e-01,  ...,  3.9731e-01,\n",
            "            8.1627e-01, -2.6756e-01],\n",
            "          [-3.5351e-01, -1.4431e-01,  8.4472e-02,  ..., -1.4039e+00,\n",
            "           -7.4922e-01,  5.8314e-01]],\n",
            "\n",
            "         [[-9.5923e-02, -2.4419e-01,  4.3229e-01,  ...,  4.8630e-01,\n",
            "            3.8399e-03, -4.2749e-01],\n",
            "          [-1.3221e-01,  1.7180e-01,  9.9726e-02,  ..., -9.1895e-01,\n",
            "           -1.6600e-01,  1.3348e-02],\n",
            "          [ 8.5339e-02,  4.0366e-01, -7.8654e-01,  ...,  1.2674e-02,\n",
            "            2.8082e-01,  3.3438e-01],\n",
            "          ...,\n",
            "          [ 1.1762e-01, -4.7202e-01,  1.4707e+00,  ..., -5.9524e-01,\n",
            "            2.2076e-01,  5.9616e-01],\n",
            "          [ 1.3433e-01,  4.6826e-01, -1.1391e-01,  ...,  4.8777e-01,\n",
            "            3.4250e-02, -1.0645e-01],\n",
            "          [ 5.6495e-02,  2.0221e-01,  1.1259e-01,  ..., -5.9181e-01,\n",
            "            3.2424e-01,  1.3593e-01]],\n",
            "\n",
            "         [[-2.2353e-01, -1.5789e-01,  4.9768e-01,  ...,  2.4673e-01,\n",
            "           -4.3041e-01, -4.0410e-01],\n",
            "          [-1.4959e-01, -2.7575e-01,  5.7217e-01,  ..., -1.0528e+00,\n",
            "            2.5812e-02,  9.0373e-01],\n",
            "          [ 1.3624e-01, -4.0778e-01,  2.3072e-01,  ...,  3.2491e-01,\n",
            "           -4.4920e-01, -1.9267e-02],\n",
            "          ...,\n",
            "          [ 1.8874e-01, -2.3859e-01,  9.1765e-04,  ..., -8.0428e-01,\n",
            "           -1.6797e-01,  5.8801e-01],\n",
            "          [ 2.9213e-01, -4.1138e-02,  7.7266e-01,  ..., -6.6867e-01,\n",
            "           -6.9572e-02, -6.4920e-01],\n",
            "          [-4.7241e-01, -2.4264e-01,  2.6615e-01,  ...,  1.1372e-01,\n",
            "            2.9621e-01,  2.7565e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.4074e-01,  6.5533e-02, -2.8680e-01,  ..., -1.3935e-01,\n",
            "           -3.2219e-01,  2.8361e-01],\n",
            "          [ 6.7640e-01, -3.4582e-01,  5.4139e-01,  ...,  2.2292e-01,\n",
            "           -5.3221e-01,  3.8499e-01],\n",
            "          [ 2.0252e-01, -6.4129e-01,  2.0002e-01,  ...,  2.4503e-01,\n",
            "           -7.5573e-01,  6.4845e-02],\n",
            "          ...,\n",
            "          [ 2.4324e-01, -1.8591e-01,  1.6726e-01,  ...,  1.6198e-01,\n",
            "           -5.9591e-01,  3.5624e-01],\n",
            "          [-5.7956e-02, -1.8805e-01, -3.0010e-01,  ...,  2.9489e-01,\n",
            "           -6.5272e-02,  9.0546e-02],\n",
            "          [-2.7508e-01, -6.6869e-01,  1.4696e-01,  ..., -3.8128e-01,\n",
            "            1.6960e-01,  2.5940e-01]],\n",
            "\n",
            "         [[ 4.9083e-01,  2.6922e-02, -1.0104e-01,  ...,  1.7139e-02,\n",
            "           -2.7135e-01, -2.6266e-01],\n",
            "          [-1.6307e-01,  4.3800e-01, -6.6532e-01,  ...,  8.1953e-01,\n",
            "           -1.8895e-02,  3.2335e-01],\n",
            "          [ 8.1355e-02,  7.6086e-01,  3.5445e-01,  ..., -4.9182e-01,\n",
            "            3.1403e-01, -3.6377e-02],\n",
            "          ...,\n",
            "          [ 1.7524e-01, -3.7604e-02,  5.4507e-01,  ..., -9.9902e-01,\n",
            "            3.5659e-01,  9.3046e-01],\n",
            "          [ 1.5657e-01,  3.0912e-01,  3.4505e-01,  ..., -3.2454e-01,\n",
            "           -1.9967e-01, -3.2285e-01],\n",
            "          [ 2.8309e-01, -4.2394e-01, -2.0914e-01,  ..., -2.3199e-01,\n",
            "            5.0996e-01, -3.5725e-01]],\n",
            "\n",
            "         [[ 1.4963e-01, -8.7485e-02,  8.3893e-01,  ...,  1.8239e-01,\n",
            "           -8.6101e-02, -6.9505e-02],\n",
            "          [-5.6145e-02, -8.6462e-02,  9.6149e-01,  ...,  5.9708e-01,\n",
            "            2.3006e-01, -2.4329e-01],\n",
            "          [-2.5849e-01, -1.0353e-01,  1.0008e+00,  ..., -8.2858e-01,\n",
            "            1.4425e-01,  4.0559e-01],\n",
            "          ...,\n",
            "          [-8.4053e-01,  1.6432e+00,  3.3324e-01,  ...,  5.6522e-01,\n",
            "            2.3773e-01, -3.4549e-01],\n",
            "          [-4.9328e-01,  1.6593e-01,  3.3015e-01,  ..., -3.3374e-01,\n",
            "           -5.9766e-01,  2.3991e-01],\n",
            "          [ 3.7135e-01, -8.8670e-02,  2.7348e-01,  ..., -2.1569e-01,\n",
            "            3.9059e-01,  1.8950e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.1681e-02,  5.0232e-01,  5.1848e-01,  ...,  1.8345e-01,\n",
            "           -1.2198e-01,  6.1317e-01],\n",
            "          [ 1.4027e-01,  8.8706e-01,  1.0917e-02,  ..., -3.7776e-01,\n",
            "           -5.9941e-01, -1.7334e-01],\n",
            "          [ 4.2779e-01, -5.0592e-01, -1.1069e-01,  ...,  6.7313e-01,\n",
            "            1.9207e-01, -4.8768e-02],\n",
            "          ...,\n",
            "          [ 4.5546e-01,  6.0677e-01, -3.1462e-01,  ..., -6.3746e-01,\n",
            "           -4.2086e-01,  4.5041e-01],\n",
            "          [ 2.8197e-01,  2.2738e-01, -1.3376e+00,  ..., -1.8345e-01,\n",
            "           -2.6999e-01,  2.3671e-01],\n",
            "          [ 2.0798e-01, -1.2777e-01, -7.3226e-01,  ...,  6.0432e-02,\n",
            "           -1.6563e-02, -2.4856e-01]],\n",
            "\n",
            "         [[ 5.2612e-01,  4.9291e-01,  1.9722e-02,  ...,  6.0892e-01,\n",
            "            1.7684e-01,  5.1031e-01],\n",
            "          [ 8.1886e-02, -3.5875e-01, -5.0866e-01,  ..., -7.2689e-02,\n",
            "           -8.1986e-01,  1.4171e-01],\n",
            "          [ 2.4645e-01, -1.2518e-01, -3.0835e-01,  ..., -6.9982e-01,\n",
            "            2.6709e-01,  7.0577e-01],\n",
            "          ...,\n",
            "          [-3.1385e-02,  7.0202e-02, -1.8909e-01,  ...,  1.0976e+00,\n",
            "            3.7408e-01,  2.5731e-01],\n",
            "          [-5.7288e-01,  2.9503e-01, -2.8573e-01,  ...,  1.6637e-02,\n",
            "            7.0736e-01, -5.0356e-02],\n",
            "          [ 4.5774e-01, -1.2432e-01, -2.7444e-01,  ..., -1.1900e-01,\n",
            "           -5.6304e-02, -1.6240e-01]],\n",
            "\n",
            "         [[-2.6250e-02,  3.7380e-01, -3.0691e-01,  ...,  7.8526e-01,\n",
            "           -2.7018e-01, -1.3219e-01],\n",
            "          [-5.0264e-02, -4.4692e-01, -5.8789e-01,  ..., -3.9851e-01,\n",
            "           -5.7844e-01, -4.4375e-02],\n",
            "          [ 4.8207e-01, -2.8088e-02, -1.8630e-01,  ...,  1.1892e-01,\n",
            "           -1.4497e-01, -3.1334e-01],\n",
            "          ...,\n",
            "          [-2.0109e-01, -1.9836e-01, -4.9073e-01,  ...,  1.1579e+00,\n",
            "            5.2649e-01, -3.1128e-01],\n",
            "          [ 1.6014e-01,  2.7442e-02, -5.1682e-01,  ...,  7.8998e-02,\n",
            "           -3.2828e-01, -6.2409e-01],\n",
            "          [ 2.2194e-01,  5.1275e-02, -8.4495e-01,  ...,  6.1711e-02,\n",
            "           -2.5756e-01, -4.3966e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3210e-01,  5.5982e-01, -1.8154e-01,  ..., -2.7395e-01,\n",
            "           -3.4837e-01,  1.1793e-02],\n",
            "          [ 1.4813e-01, -2.4518e-01,  5.9551e-01,  ..., -3.9052e-02,\n",
            "            4.9080e-01,  1.9625e-01],\n",
            "          [-5.0804e-01,  1.9062e-01, -6.1785e-01,  ..., -5.2591e-02,\n",
            "            6.7255e-01,  3.7159e-01],\n",
            "          ...,\n",
            "          [ 8.1316e-02,  2.7014e-03, -3.4007e-01,  ...,  5.6020e-01,\n",
            "            1.6575e-02,  6.0173e-01],\n",
            "          [ 1.0782e+00,  2.8693e-01, -8.0218e-01,  ..., -2.6846e-01,\n",
            "           -8.6848e-01,  4.0913e-01],\n",
            "          [ 3.2831e-01,  7.5709e-01,  9.7364e-02,  ...,  3.1412e-01,\n",
            "            2.6991e-01,  5.8429e-01]],\n",
            "\n",
            "         [[-4.6257e-01, -2.3859e-01, -2.6820e-01,  ...,  1.3498e-02,\n",
            "            2.1177e-01,  7.8209e-02],\n",
            "          [ 6.6248e-01, -2.3100e-01, -6.4004e-01,  ...,  2.6157e-02,\n",
            "            4.0029e-01,  3.3725e-01],\n",
            "          [ 2.5001e-01,  4.8494e-01, -1.2148e-01,  ...,  5.9161e-01,\n",
            "           -4.4582e-01,  5.0922e-01],\n",
            "          ...,\n",
            "          [ 1.5491e-02, -4.1576e-01,  2.2821e-01,  ...,  1.0718e-01,\n",
            "           -1.3913e-01,  3.5919e-01],\n",
            "          [-3.1313e-01,  4.8027e-01, -1.8447e-01,  ...,  6.9373e-02,\n",
            "           -1.3699e-01,  6.3315e-01],\n",
            "          [ 1.8410e-01,  1.0308e+00, -2.7002e-01,  ..., -3.8821e-01,\n",
            "            9.0679e-02, -2.2881e-01]],\n",
            "\n",
            "         [[ 1.9650e-02, -1.2870e-01, -1.2693e-01,  ..., -1.7463e-01,\n",
            "            1.6531e-01,  2.3372e-01],\n",
            "          [-9.3252e-02,  8.7316e-02, -1.7272e-01,  ..., -9.2842e-01,\n",
            "            1.5615e-01,  3.4734e-01],\n",
            "          [ 4.2991e-01,  3.5243e-02,  1.4818e+00,  ..., -1.4555e+00,\n",
            "           -3.2179e-01, -7.1087e-01],\n",
            "          ...,\n",
            "          [ 1.5256e-01, -1.6760e-01,  8.8690e-01,  ...,  1.1522e+00,\n",
            "            4.7168e-01, -5.9185e-01],\n",
            "          [ 3.4255e-01, -2.7554e-03,  1.9194e-02,  ...,  6.7763e-01,\n",
            "            3.6814e-01,  6.2894e-02],\n",
            "          [ 3.4731e-01, -6.0463e-01,  2.7471e-01,  ..., -1.2364e-01,\n",
            "            8.9759e-02, -5.3933e-01]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
          ]
        }
      ],
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) # dilation = 패딩 사이의 간격\n",
        "\n",
        "input = torch.randn(20, 16, 50 ,100)\n",
        "print(input)\n",
        "output = m(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RLqGbclbp3_N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 26, 100])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYeGAJEuneqW"
      },
      "source": [
        "### nn.functional 패키지\n",
        "\n",
        "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
        "\n",
        "- 예시)\n",
        "  - Convolution functions\n",
        "\n",
        "  - Pooling functions\n",
        "  \n",
        "  - Non-linear activation functions\n",
        "\n",
        "  - Normalization functions\n",
        "\n",
        "  - Linear functions\n",
        "\n",
        "  - Dropout functions\n",
        "  \n",
        "  - Sparse functions\n",
        "  \n",
        "  - Distance functions\n",
        "\n",
        "  - Loss functions\n",
        "  - ..\n",
        "\n",
        "- https://pytorch.org/docs/stable/nn.functional.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpwbO9Dhpflm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYaJ5aLqKed"
      },
      "source": [
        "- Convolution Layer 예시 (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAWLQE2GouHP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWmSlFBrpms1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wah4RsmgrRDP"
      },
      "source": [
        "## Torchvision\n",
        "\n",
        "- `transforms`: 전처리할 때 사용하는 메소드\n",
        "\n",
        "- `transforms`에서 제공하는 클래스 이외에  \n",
        "  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
        "  \n",
        "  - 아래의 코드에서 다양한 전처리 기술 확인  \n",
        "    https://pytorch.org/docs/stable/torchvision/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akvq4QWmqSil"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKu5mzyTs-Qj"
      },
      "source": [
        "- 예시)\n",
        "  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n",
        "\n",
        "  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
        "\n",
        "  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n",
        "   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6K7FH-Rs9my"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4l1GvIlslKa"
      },
      "source": [
        "## utils.data\n",
        "\n",
        "- `Dataset`에는 다양한 데이터셋이 존재  \n",
        "  - MNIST, CIFAR10, ...\n",
        "\n",
        "- `DataLoader`, `Dataset`을 통해  \n",
        "  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wsZKY7-s2Vv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lldpI2lquBu3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKddZnT1uQmT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxymquLxeo8"
      },
      "source": [
        "- `batch_size`만큼 데이터를 하나씩 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvgMIyF6uUuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUC0a0aw6OM"
      },
      "source": [
        "<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n",
        "\n",
        "- `channel first`\n",
        "\n",
        "- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhylD3iyFYr"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9hAQmQlul8P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDcUY6o4xUQp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZmPWiGbxoiW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUOdd4UaxaXO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDQfjw4wxr1z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDCVw59ax3-A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcWQlxzihtS"
      },
      "source": [
        "## 각 Layer 설명"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGXn1_weif5H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kJ3heBi26y"
      },
      "source": [
        "### nn.Conv2d\n",
        "\n",
        "- `in_channels`: channel의 갯수\n",
        "\n",
        "- `out_channels`: 출력 채널의 갯수\n",
        "\n",
        "- `kernel_size`: 커널(필터) 사이즈\n",
        "\n",
        "- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcHJguyFipTl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWiJbViHjFG0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWYFm2xjUeN"
      },
      "source": [
        "- `wegiht`확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za0enRbyjPzV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZcTU2gjiCX"
      },
      "source": [
        "- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eN_oUBkjT85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwso9tsijmz8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUegf6HPjdPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMeTOqVmcdWa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvolnNsscdHs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLOAfD5mjup1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r50wFkl6j1sY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiIp-frJj2Hl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOHMu-UQkW3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCqGmH_kwHm"
      },
      "source": [
        "### Pooling\n",
        "- `F.max_pool2d` \n",
        "  - `stride`\n",
        "\n",
        "  - `kernel_size`\n",
        "\n",
        "- `torch.nn.MaxPool2d` 도 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYqPrLH1kxQl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvI8W_8Yk81S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3HK4FulCaJ"
      },
      "source": [
        "- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fseB_qlflBta"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w8DQnNtlNCq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RVioKwlbH1"
      },
      "source": [
        "### Linear\n",
        "- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwcedadrlcbl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mYQy4I3lmAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wgSmY0Zlofk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcJFqf0alsxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewEpebSVluHz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjPKDKRl3CV"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obhBb3O-lzbs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljgOEyNMmBEE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ymFSRAmBo7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh13Bnj5wEN"
      },
      "source": [
        "### F.relu\n",
        "\n",
        "- ReLU 함수를 적용하는 레이어\n",
        "\n",
        "- `nn.ReLU`로도 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4VFePpR9_Ak"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lKlSiaY5wZW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "- `import torch.optim as optim`\n",
        "\n",
        "- `model`의 파라미터를 업데이트\n",
        "\n",
        "- 예시)\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "- `.zero_grad()`로 초기화\n",
        "- `.step()`으로 업데이트\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "_9 파이토치(PyTorch) 기초.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
