{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Xx-jP92OgP"
      },
      "source": [
        "# 파이토치(PyTorch)\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n",
        "\n",
        "- 코드 출처: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cxreguz2sL0"
      },
      "source": [
        "## 파이토치의 구성요소\n",
        "\n",
        "- `torch`: 텐서를 생성하는 라이브러리\n",
        "\n",
        "- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.nn`: 신경망을 생성하는 라이브러리\n",
        "\n",
        "- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n",
        "\n",
        "- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n",
        "\n",
        "- `torch.onnx`: ONNX(Open Neural Network Exchange)\n",
        "\n",
        "  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5O_aSvtHvb"
      },
      "source": [
        "## 텐서(Tensors)\n",
        "- 넘파이(NumPy)의 ndarray와 유사\n",
        "\n",
        "- GPU를 사용한 연산 가속도 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CmKIvnx0s8G6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "49IHV-qJE5FI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.7.1'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUHVy-gtZeT"
      },
      "source": [
        "### 초기화 되지 않은 행렬 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3PqY3cZatU0D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCIJ2pNteZv"
      },
      "source": [
        "### 무작위로 초기화된 행렬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h6oPj2Q9tdYx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1364, 0.4878],\n",
            "        [0.1146, 0.3116],\n",
            "        [0.7900, 0.3541],\n",
            "        [0.5430, 0.9910]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5aHphIHtiJk"
      },
      "source": [
        "### dtype이 long, 0으로 채워진 텐서"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(4, 2, dtype=torch.long)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W4VL8C_ctu8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.0000, 2.3000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([3, 2.3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4RmVBVtIt46M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 4, dtype=torch.double)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xxskTUfGuPUe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn_like(x, dtype=torch.float) # x 모양은 그대로 가져오되, 랜덤으로 채움\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5sGxGvucpH"
      },
      "source": [
        "### 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yy-JbqKEuYIR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(x.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehOg0eDwufru"
      },
      "source": [
        "## 텐서의 연산(operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Doc_37uh3G"
      },
      "source": [
        "### 덧셈 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rw4JCYkYuef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wa44ur1Nuj5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6724, 0.2491, 0.0728, 0.8664],\n",
            "        [0.7221, 0.4772, 0.3406, 0.5142]])\n",
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(2, 4)\n",
        "print(y)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5gcOo-Ouo9B"
      },
      "source": [
        "### 덧셈2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Qx-NzJhhumZx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvrQhLuuuIr"
      },
      "source": [
        "### 덧셈3\n",
        "- 결과 텐서를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lUsLAOTcur1-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(2, 4)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BdyZFSu2Ei"
      },
      "source": [
        "### 덧셈4\n",
        "- `in-place` 방식\n",
        "\n",
        "- (참고) in-place 방식\n",
        "  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n",
        "  - `x.copy_(y), x.t_()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lu8rR4WVu0wQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7305, -0.4693,  0.6571,  0.2785],\n",
            "        [ 0.3458, -2.0419,  0.7104, -0.9456]])\n",
            "tensor([[0.6724, 0.2491, 0.0728, 0.8664],\n",
            "        [0.7221, 0.4772, 0.3406, 0.5142]])\n",
            "tensor([[ 1.4029, -0.2203,  0.7299,  1.1449],\n",
            "        [ 1.0678, -1.5647,  1.0510, -0.4314]])\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "print(y)\n",
        "y.add_(x) # y += x\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8nsrGjOw6W"
      },
      "source": [
        "### 그 외의 연산\n",
        "- `torch.sub` : 뺄셈\n",
        "\n",
        "- `torch.mul` : 곱셉\n",
        "\n",
        "- `torch.div` : 나눗셈\n",
        "\n",
        "- `torch.mm` : 내적(dot product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S51kxzPTO1ER"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ou0dY8mkPR24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2.,  8.],\n",
            "        [30., 56.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6RlZZBp3PbE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.8333, 0.8750]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1,2],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7MR-ofE5P7VC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[20., 28.],\n",
            "        [52., 76.]])\n"
          ]
        }
      ],
      "source": [
        "# 행렬 곱\n",
        "\n",
        "x = torch.Tensor([[1, 3],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])\n",
        "print(torch.mm(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URGwHE_NjDi"
      },
      "source": [
        "## 텐서의 조작(manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCsdZIPTvG53"
      },
      "source": [
        "### 인덱싱\n",
        "- 넘파이처럼 인덱싱 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jF2DE8kzvOs3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [5., 7.]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GQtBH3r3u7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 7.])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEscXddKvQ5l"
      },
      "source": [
        "### view\n",
        "- 텐서의 크기(size)나 모양(shape)을 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xwhWeqhLvKKj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 5])\n",
            "torch.Size([20])\n",
            "torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 5)\n",
        "y = x.view(20)\n",
        "z = x.view(5, -1)\n",
        "\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBY_wuIRvf5j"
      },
      "source": [
        "### item\n",
        "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "E0W24QqpvcmV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.5796])\n",
            "-0.5796216130256653\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # item은 실제 존재하는 값을 출력\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1sCUVwC3Nua"
      },
      "source": [
        "- 스칼라값 하나만 존재해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jl4_FAgd3Lt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0163, -0.5312])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-7c023f92a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThndsy5M6wM"
      },
      "source": [
        "### squeeze \n",
        "- 차원을 축소(제거)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OF3rOavnRxgM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Y2jq0jHJR5Jw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9965, 0.4982, 0.9327],\n",
            "        [0.1674, 0.9794, 0.7687],\n",
            "        [0.4964, 0.0900, 0.7723]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.squeeze()\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv-dnTYNJ8Z"
      },
      "source": [
        "### unsqueeze\n",
        "- 차원을 증가(생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PFxaHGY1NOBo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0.0090, 0.3771, 0.2244],\n",
            "         [0.4832, 0.5697, 0.9270],\n",
            "         [0.1131, 0.1186, 0.2343]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "b6sa4tJ7SA8G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0090, 0.3771, 0.2244],\n",
            "          [0.4832, 0.5697, 0.9270],\n",
            "          [0.1131, 0.1186, 0.2343]]]])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.unsqueeze(dim=0)\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_oa9JANOa6"
      },
      "source": [
        "### stack\n",
        "- 텐서간 결합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "f3x_XaUYNOuc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([1,4])\n",
        "y = torch.FloatTensor([2,5])\n",
        "z = torch.FloatTensor([3,6])\n",
        "\n",
        "print(torch.stack([x, y, z]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJscbfg35-c"
      },
      "source": [
        "### cat\n",
        "- 텐서를 결합하는 메소드(concatenate)\n",
        "\n",
        "- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n",
        "  - 예를 들어, 해당 차원을 늘려준 후 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Mv3zlaNm37P1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.1752,  0.1866, -1.5733],\n",
            "          [ 0.6942, -0.3779,  1.4861],\n",
            "          [-0.6168, -0.2004,  0.5868]]],\n",
            "\n",
            "\n",
            "        [[[-0.5854,  0.0159, -0.9685],\n",
            "          [-0.4702,  2.1106, -0.7855],\n",
            "          [ 1.2723,  0.2302,  0.5311]]]])\n",
            "torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.3662,  1.5685, -0.0570],\n",
            "          [ 1.1396, -0.0481,  0.2125],\n",
            "          [ 0.0467,  1.5326, -1.4442]]],\n",
            "\n",
            "\n",
            "        [[[-1.7959,  0.3558,  0.7515],\n",
            "          [ 1.7988, -0.6035, -0.1324],\n",
            "          [-0.0990,  0.0146,  0.8388]]]])\n",
            "torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "69M5jY60S7Mi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.3882,  0.8124, -0.2160],\n",
            "         [-1.5805, -0.0826,  0.8876],\n",
            "         [-0.1478,  0.7554,  0.2387],\n",
            "         [ 0.6822,  1.2933,  1.1244],\n",
            "         [-0.0926,  0.5437, -0.0403],\n",
            "         [-1.2582, -0.4290, -1.2237]]])\n",
            "torch.Size([1, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 3, 3)\n",
        "b = torch.randn(1, 3, 3)\n",
        "c = torch.cat((a, b), dim=1)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGXnOAqQTmG"
      },
      "source": [
        "### chuck\n",
        "- 텐서를 여러 개로 나눌 때 사용\n",
        "\n",
        "- 몇 개의 텐서로 나눌 것이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pNV80VzPQZgG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1922, 0.7639, 0.9714, 0.9910, 0.5425, 0.6984],\n",
            "        [0.0602, 0.0840, 0.4190, 0.2966, 0.7102, 0.1967],\n",
            "        [0.0583, 0.5205, 0.8379, 0.5632, 0.2177, 0.3999]])\n",
            "tensor([[0.1922, 0.7639],\n",
            "        [0.0602, 0.0840],\n",
            "        [0.0583, 0.5205]])\n",
            "tensor([[0.9714, 0.9910],\n",
            "        [0.4190, 0.2966],\n",
            "        [0.8379, 0.5632]])\n",
            "tensor([[0.5425, 0.6984],\n",
            "        [0.7102, 0.1967],\n",
            "        [0.2177, 0.3999]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.chunk(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Qb0jWQgm-"
      },
      "source": [
        "### split\n",
        "- `chunck`와 동일한 기능이지만 조금 다름\n",
        "\n",
        "- 하나의 텐서당 크기가 얼마이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7099, 0.3394, 0.4006, 0.7464, 0.6270, 0.2052],\n",
            "        [0.7251, 0.9333, 0.6631, 0.1988, 0.6035, 0.5055],\n",
            "        [0.6480, 0.6004, 0.9905, 0.1201, 0.4180, 0.3201]])\n",
            "tensor([[0.7099, 0.3394, 0.4006],\n",
            "        [0.7251, 0.9333, 0.6631],\n",
            "        [0.6480, 0.6004, 0.9905]])\n",
            "tensor([[0.7464, 0.6270, 0.2052],\n",
            "        [0.1988, 0.6035, 0.5055],\n",
            "        [0.1201, 0.4180, 0.3201]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2 = torch.split(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1V6DDnLVQqxz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1180, 0.4988, 0.5982, 0.1992, 0.6785, 0.8217],\n",
            "        [0.4125, 0.5807, 0.6859, 0.2323, 0.2702, 0.6624],\n",
            "        [0.5821, 0.0659, 0.2783, 0.1323, 0.2304, 0.6171]])\n",
            "tensor([[0.1180, 0.4988],\n",
            "        [0.4125, 0.5807],\n",
            "        [0.5821, 0.0659]])\n",
            "tensor([[0.5982, 0.1992],\n",
            "        [0.6859, 0.2323],\n",
            "        [0.2783, 0.1323]])\n",
            "tensor([[0.6785, 0.8217],\n",
            "        [0.2702, 0.6624],\n",
            "        [0.2304, 0.6171]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.split(tensor, 2, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estSwhCgvta6"
      },
      "source": [
        "### torch ↔ numpy\n",
        "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
        "\n",
        "  - `numpy()`\n",
        "  - `from_numpy()`\n",
        "\n",
        "- (참고)\n",
        "  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VxHI7c_yvmAT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(7)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "whbrhokHwJ3A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "b = a.numpy()\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5StIhUWDwQjA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4., 4., 4., 4., 4., 4., 4.])\n",
            "[4. 4. 4. 4. 4. 4. 4.]\n"
          ]
        }
      ],
      "source": [
        "a.add_(1) # a에다 1이 더해짐\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3RNS5-cRwTt8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(7)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZaxSvLxEej"
      },
      "source": [
        "## CUDA Tensors\n",
        "- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
        "  - 예) cpu, gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xkaQznCRxpUj"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "SCnC0x2Rxpbk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.7280])\n",
            "1.7280490398406982\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GcSsFLkDw-nI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "tensor([2.7280], device='cuda:0')\n",
            "tensor([2.7280], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device) # 만들어진 x를 gpu로 옮기겠다\n",
        "z = x + y\n",
        "print(device)\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## AUTOGRAD (자동미분)\n",
        "- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "\n",
        "- backprop를 위한 미분값을 자동으로 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "### Tensor\n",
        "\n",
        "- data: tensor형태의 데이터\n",
        "\n",
        "- grad: data가 겨쳐온 layer에 대한 미분값 저장\n",
        "\n",
        "- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
        "\n",
        "- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n",
        "\n",
        "- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n",
        "\n",
        "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
        "\n",
        "- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ipdk_1jfx47I"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ljNU-r9p0Rpo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "or6sQ4EB0UYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 5 # by broadcast\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PuQ7xDmu0Wpj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x0000022547F68588>\n"
          ]
        }
      ],
      "source": [
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6_2iM-Zq0ZdG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[72., 72., 72.],\n",
            "        [72., 72., 72.],\n",
            "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 2\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHGROgrM0ebO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x0000022547F68748>\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 3)\n",
        "a = ((a * 3) / (a- 1))\n",
        "print(a.requires_grad)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)\n",
        "- 역전파: `.backward()`를 통해 역전파 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1tdoN9p-1kn4"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CixGTXbV1B9p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SY63Mcc-1iNI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1352.9348, -569.2090,  882.2342], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YPaVAbIT3gx_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v) # y를 backward 할 때 v를 넣음\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "weeIe5_Z3jVe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ALcth7Ew3l7H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(1)\n",
        "- 계산 흐름  \n",
        "  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "<br>\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해  \n",
        "  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n",
        "    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NUAc1etP3oBc"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tCW7dq9uB89T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-AyyGy49FLz9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SmmJa-hvFPGH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad: None\n",
            "a.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"a.data:\",a.data)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\",a.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "- $b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iUPt042iF9V1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "b = a + 2\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "- $c = b^2$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FRDS6gP0GFZG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c = b**2\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VynoiUywGSwh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v3ryJon9GeMn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out)\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "- a의 `grad_fn`이 None인 이유  \n",
        "  직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bccI4vIWGgqj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "a.grad: tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"a.data:\",a.data)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\",a.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oka1mkadHq-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b.data: tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "b.grad: None\n",
            "b.grad_fn: <AddBackward0 object at 0x00000225480DD278>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"b.data:\", b.data)\n",
        "print(\"b.grad:\", b.grad)\n",
        "print(\"b.grad_fn:\",b.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZiYNajdLccUF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c.data: tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "c.grad: None\n",
            "c.grad_fn: <PowBackward0 object at 0x00000225480DC9B0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"c.data:\", c.data)\n",
        "print(\"c.grad:\", c.grad)\n",
        "print(\"c.grad_fn:\",c.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BcLoMYite0vU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out.data: tensor(36.)\n",
            "out.grad: None\n",
            "out.grad_fn: <SumBackward0 object at 0x00000225480DC710>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"out.data:\", out.data)\n",
        "print(\"out.grad:\", out.grad)\n",
        "print(\"out.grad_fn:\", out.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXgwviHfovj"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(2)\n",
        "- `grad`값을 넣어서 `backward`\n",
        "\n",
        "- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bB6DCYXRfcI_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "y = (x ** 2)\n",
        "z = y ** 2 + x\n",
        "out = z.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AVo-glm8fvFv"
      },
      "outputs": [],
      "source": [
        "grad = torch.Tensor([0.1, 1, 100])\n",
        "z.backward(grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tdBklrepf2qq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.data: tensor([1., 1., 1.])\n",
            "x.grad: tensor([  0.5000,   5.0000, 500.0000])\n",
            "x.grad_fn: None\n"
          ]
        }
      ],
      "source": [
        "print(\"x.data:\", x.data)\n",
        "print(\"x.grad:\", x.grad)\n",
        "print(\"x.grad_fn:\", x.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HQvUGlfRf7jU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y.data: tensor([1., 1., 1.])\n",
            "y.grad: None\n",
            "y.grad_fn: <PowBackward0 object at 0x0000022547F68A58>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"y.data:\", y.data)\n",
        "print(\"y.grad:\", y.grad)\n",
        "print(\"y.grad_fn:\", y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "h7TFHdMfgxvW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z.data: tensor([2., 2., 2.])\n",
            "z.grad: None\n",
            "z.grad_fn: <AddBackward0 object at 0x0000022547F682B0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(\"z.data:\", z.data)\n",
        "print(\"z.grad:\", z.grad)\n",
        "print(\"z.grad_fn:\", z.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv-osmNmWiA"
      },
      "source": [
        "## nn & nn.functional\n",
        "\n",
        "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
        "\n",
        "- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
        "\n",
        "- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n",
        "\n",
        "- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n",
        "  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8fkKq3nWP1"
      },
      "source": [
        "### nn 패키지\n",
        "\n",
        "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n",
        "  - 따라서, `weight`값들을 직접 선언 안함\n",
        "\n",
        "- 예시\n",
        "  - Containers\n",
        "\n",
        "  - Convolution Layers\n",
        "\n",
        "  - Pooling layers\n",
        "\n",
        "  - Padding Layers\n",
        "\n",
        "  - Non-linear Activations (weighted sum, nonlinearity)\n",
        "\n",
        "  - Non-linear Activations (other)\n",
        "\n",
        "  - Normalization Layers\n",
        "\n",
        "  - Recurrent Layers\n",
        "\n",
        "  - Transformer Layers\n",
        "\n",
        "  - Linear Layers\n",
        "\n",
        "  - Dropout Layers\n",
        "\n",
        "  - Sparse Layers\n",
        "\n",
        "  - Distance Functions\n",
        "\n",
        "  - Loss Functions\n",
        "\n",
        "  - ..\n",
        "- https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8tEtWHAsmZMy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjCbeEQqPSI"
      },
      "source": [
        "- Convolution Layer 예시 (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NQ7Y0tCOpkhM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 1.5369e-01, -1.1988e+00,  1.2930e+00,  ..., -2.0816e-01,\n",
            "           -5.7843e-01, -3.7663e-01],\n",
            "          [-3.1767e-01, -2.6724e+00, -6.4373e-01,  ...,  3.4081e-01,\n",
            "           -5.8146e-01,  8.3539e-01],\n",
            "          [-2.9369e-01,  5.9791e-01, -5.1090e-01,  ...,  1.1004e+00,\n",
            "            3.5490e-03,  1.8418e+00],\n",
            "          ...,\n",
            "          [ 2.9820e-02, -3.6088e-01,  2.2031e-01,  ..., -8.1506e-01,\n",
            "            3.8092e-01, -1.2579e-01],\n",
            "          [ 6.6572e-01, -7.0657e-02,  3.9870e-02,  ..., -1.5741e+00,\n",
            "           -8.5371e-02, -4.8397e-01],\n",
            "          [ 2.9279e-02,  6.4186e-02,  1.9752e-01,  ...,  1.7173e+00,\n",
            "           -1.3983e-01,  3.9611e-02]],\n",
            "\n",
            "         [[ 5.0685e-01, -1.1660e+00,  1.8460e+00,  ...,  2.1293e+00,\n",
            "            1.8949e-01, -8.3017e-01],\n",
            "          [-2.0222e-01, -1.0570e+00, -1.9730e+00,  ...,  1.0664e+00,\n",
            "            1.8952e+00,  9.2311e-03],\n",
            "          [ 7.0666e-01,  1.6990e+00,  3.1035e-01,  ..., -1.9211e+00,\n",
            "           -9.7900e-02, -2.2241e-01],\n",
            "          ...,\n",
            "          [-2.2096e-02, -7.9794e-02,  2.6555e+00,  ..., -2.7057e-01,\n",
            "           -2.4682e-01,  1.7614e+00],\n",
            "          [-6.9565e-01,  7.1237e-02, -7.7482e-01,  ..., -6.7707e-01,\n",
            "           -4.1546e-01,  9.1943e-01],\n",
            "          [-1.3753e+00,  1.2446e+00,  1.5059e-01,  ..., -8.7573e-02,\n",
            "            4.2666e-01,  7.1474e-01]],\n",
            "\n",
            "         [[-7.9996e-02,  5.9620e-01, -3.3671e-01,  ...,  1.2152e+00,\n",
            "            2.7949e-01, -1.0542e-01],\n",
            "          [ 2.1604e-01, -2.2390e-01,  8.1435e-01,  ..., -9.5663e-01,\n",
            "            5.7107e-01, -2.5078e-01],\n",
            "          [-1.8695e-01,  2.7880e-01,  7.7878e-01,  ..., -1.1466e+00,\n",
            "           -1.8607e-01, -7.6171e-01],\n",
            "          ...,\n",
            "          [ 1.1848e+00,  1.5636e-01,  3.3301e-01,  ...,  6.9807e-01,\n",
            "            1.0966e+00,  2.6886e-01],\n",
            "          [-1.0481e+00, -7.0676e-01,  8.8147e-01,  ...,  9.3132e-01,\n",
            "           -1.5753e+00, -3.3982e-01],\n",
            "          [ 5.9221e-01,  8.8064e-01, -3.1186e-02,  ...,  4.8345e-01,\n",
            "            5.7096e-01,  6.0146e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.0646e-01, -9.3654e-01,  3.4530e-01,  ..., -1.5318e-01,\n",
            "            1.2730e+00, -2.6094e-01],\n",
            "          [ 6.2378e-02, -9.3779e-01, -6.8781e-01,  ..., -5.9014e-01,\n",
            "            6.7717e-01, -2.0767e+00],\n",
            "          [-1.5329e+00,  5.1185e-01, -8.4252e-01,  ..., -8.5360e-01,\n",
            "           -4.4604e-01, -1.4152e+00],\n",
            "          ...,\n",
            "          [-4.4216e-01,  4.7127e-01, -2.2422e+00,  ...,  1.7634e+00,\n",
            "           -4.9827e-01, -8.8652e-01],\n",
            "          [-1.8883e+00, -7.9304e-01,  6.1302e-01,  ..., -2.3418e-01,\n",
            "           -1.7948e+00, -2.6331e-01],\n",
            "          [-1.0015e+00,  9.4278e-01, -9.2586e-01,  ...,  1.3685e+00,\n",
            "           -7.6362e-02,  9.7162e-01]],\n",
            "\n",
            "         [[-1.1449e+00,  4.2009e-01,  1.4556e+00,  ...,  1.3087e+00,\n",
            "           -1.3635e+00,  4.1254e-01],\n",
            "          [ 7.8704e-01, -4.5447e-01,  1.3084e+00,  ...,  2.2434e+00,\n",
            "            1.3561e-01, -3.5772e-01],\n",
            "          [-2.5205e-01, -1.1299e+00,  2.1950e-01,  ..., -5.3884e-01,\n",
            "            2.2866e-01,  3.2035e-01],\n",
            "          ...,\n",
            "          [ 9.3884e-02,  1.2085e+00, -8.6572e-01,  ...,  5.0707e-01,\n",
            "            1.0711e+00,  3.9369e-02],\n",
            "          [-1.2205e+00, -1.0148e-01,  2.8043e-01,  ...,  5.4957e-01,\n",
            "           -8.3347e-01,  4.1888e-01],\n",
            "          [-6.5089e-01, -3.0247e-01,  2.8021e-01,  ...,  1.2634e+00,\n",
            "           -1.4315e-01, -4.1446e-01]],\n",
            "\n",
            "         [[ 1.3166e-01,  6.0484e-02,  1.0740e+00,  ...,  1.4371e+00,\n",
            "            6.3129e-01,  1.3037e+00],\n",
            "          [-5.7152e-01, -4.8384e-01,  6.0574e-02,  ...,  9.4254e-01,\n",
            "            6.5332e-01,  7.6170e-01],\n",
            "          [ 6.2030e-01, -4.0981e-01, -1.4441e+00,  ...,  1.5682e+00,\n",
            "            1.0897e+00,  1.2912e+00],\n",
            "          ...,\n",
            "          [-7.0559e-01, -1.4071e+00, -2.6025e+00,  ...,  2.9956e-01,\n",
            "           -3.6345e-01,  1.0074e-01],\n",
            "          [-1.0995e+00,  3.7045e-01, -1.1549e+00,  ...,  4.1156e-01,\n",
            "           -1.1294e+00, -1.7338e+00],\n",
            "          [-8.0577e-01,  8.7932e-01, -1.0101e+00,  ...,  7.2463e-01,\n",
            "           -1.4926e-01,  1.8770e+00]]],\n",
            "\n",
            "\n",
            "        [[[-7.0698e-01, -1.4327e+00, -4.1357e-01,  ..., -3.4327e-01,\n",
            "           -1.6733e+00, -6.4449e-02],\n",
            "          [-7.6217e-01, -3.3681e-01,  1.7981e+00,  ...,  1.4484e+00,\n",
            "            1.5169e+00, -1.3515e-01],\n",
            "          [ 1.8527e+00,  9.8895e-02,  2.5434e-01,  ...,  2.3245e-01,\n",
            "           -1.2735e+00, -1.6081e-01],\n",
            "          ...,\n",
            "          [-2.2077e+00, -4.2999e-01, -7.2908e-01,  ..., -1.6929e+00,\n",
            "           -7.7408e-01, -1.4250e+00],\n",
            "          [ 1.0609e-01,  4.7965e-01, -5.3652e-01,  ..., -4.3321e-01,\n",
            "            3.9112e-01, -9.9970e-01],\n",
            "          [-3.5609e-01,  1.6319e+00, -9.2390e-01,  ..., -1.3846e+00,\n",
            "            6.1983e-01, -4.3701e-01]],\n",
            "\n",
            "         [[ 1.0722e+00, -2.5971e-01, -1.6418e+00,  ...,  9.6178e-01,\n",
            "            6.8713e-01, -1.8792e-01],\n",
            "          [ 4.4760e-01,  1.3541e-02,  8.0692e-02,  ..., -1.1402e+00,\n",
            "            8.9731e-01,  5.5972e-01],\n",
            "          [-9.5101e-01, -1.7141e+00, -6.5893e-01,  ...,  6.5822e-01,\n",
            "           -6.7662e-01,  1.6345e+00],\n",
            "          ...,\n",
            "          [-1.8013e+00,  2.1801e+00,  1.6727e+00,  ...,  1.7377e+00,\n",
            "            9.1120e-01, -2.0429e-01],\n",
            "          [ 5.2218e-01,  2.4372e+00, -9.3921e-01,  ...,  1.1565e+00,\n",
            "            1.2606e+00, -5.7499e-01],\n",
            "          [ 2.9173e-01,  1.1542e+00,  1.5458e-02,  ..., -1.0656e+00,\n",
            "            6.1443e-02, -3.1902e+00]],\n",
            "\n",
            "         [[ 2.9740e-01, -5.7159e-01, -9.4510e-01,  ...,  8.0784e-01,\n",
            "           -1.1788e+00, -1.2137e+00],\n",
            "          [ 1.4210e+00,  4.6241e-01,  1.8213e+00,  ..., -2.5070e-01,\n",
            "           -1.5692e+00,  2.0868e-01],\n",
            "          [ 1.7833e+00,  7.7507e-01, -1.0715e-01,  ..., -1.0090e+00,\n",
            "           -1.2506e+00, -2.0982e-03],\n",
            "          ...,\n",
            "          [ 1.2807e+00, -1.1200e-01, -4.2308e-01,  ..., -6.0141e-01,\n",
            "           -2.5830e-01,  4.6441e-01],\n",
            "          [-1.1615e+00,  7.1127e-01, -6.5417e-01,  ..., -3.3970e-01,\n",
            "            3.2696e-01, -1.3066e+00],\n",
            "          [ 5.5797e-02,  8.6509e-01,  1.1448e+00,  ..., -1.8115e-01,\n",
            "            2.6359e-01,  1.2104e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9912e-02,  1.8252e+00, -1.8506e+00,  ..., -4.4957e-01,\n",
            "           -2.5263e+00,  7.3566e-01],\n",
            "          [ 3.2341e-01, -9.2920e-01,  2.3487e+00,  ..., -1.3568e+00,\n",
            "           -1.5277e+00,  9.8719e-01],\n",
            "          [-1.6059e-01, -8.2595e-01, -4.9241e-01,  ..., -3.2894e-01,\n",
            "            7.6975e-01, -1.2930e+00],\n",
            "          ...,\n",
            "          [-1.0984e+00,  1.1441e+00, -1.2363e-02,  ...,  7.1524e-01,\n",
            "            4.0245e-01,  2.0141e+00],\n",
            "          [-4.0743e-01, -1.3435e+00,  1.8699e-01,  ..., -4.9973e-01,\n",
            "           -5.9792e-02, -2.1671e-01],\n",
            "          [-2.5372e-01, -2.4684e+00,  9.4367e-02,  ..., -2.8304e-01,\n",
            "            1.2739e+00,  1.2826e-01]],\n",
            "\n",
            "         [[ 2.5229e-01, -3.6199e-01, -5.4059e-01,  ..., -4.0487e-01,\n",
            "            1.2096e-01,  4.3110e-01],\n",
            "          [ 9.3873e-01, -1.6744e+00,  1.4569e-01,  ..., -1.4867e+00,\n",
            "           -6.6143e-01, -3.5468e-01],\n",
            "          [ 1.9843e+00, -1.0391e+00,  3.8572e-01,  ...,  1.5611e-01,\n",
            "           -5.6706e-01, -5.2140e-03],\n",
            "          ...,\n",
            "          [-3.5696e-01, -1.1141e+00,  1.7611e+00,  ...,  1.3690e-02,\n",
            "            2.3068e-01, -6.8061e-01],\n",
            "          [ 1.8843e+00,  3.9139e-01,  3.6311e-01,  ...,  2.7031e-01,\n",
            "           -1.8971e-01,  6.1016e-01],\n",
            "          [-5.0710e-01,  2.8283e-01, -3.9562e-01,  ...,  3.4205e-01,\n",
            "           -1.5198e+00, -3.7633e-01]],\n",
            "\n",
            "         [[ 1.1880e+00,  9.7328e-01,  4.4324e-01,  ..., -9.2894e-01,\n",
            "           -1.0322e-01, -6.9995e-01],\n",
            "          [ 3.4319e-01, -5.4520e-01, -7.3760e-01,  ...,  1.3348e+00,\n",
            "            1.0485e+00,  1.0582e+00],\n",
            "          [-1.7016e-01, -3.9355e-01,  4.9132e-02,  ..., -5.0120e-02,\n",
            "            1.9100e+00, -8.1238e-01],\n",
            "          ...,\n",
            "          [ 1.6782e+00,  8.2784e-01,  6.9123e-01,  ..., -1.8377e+00,\n",
            "            5.0768e-01,  1.2701e-01],\n",
            "          [-9.9785e-02, -5.3027e-01, -2.9574e-01,  ...,  7.0529e-01,\n",
            "            9.4121e-01,  5.7882e-01],\n",
            "          [ 7.1377e-01,  1.1225e+00,  1.7581e+00,  ...,  1.3771e+00,\n",
            "            1.7470e-01, -1.6291e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0300e+00, -6.2418e-01,  7.9722e-01,  ...,  8.1278e-03,\n",
            "            4.0797e-01, -1.4724e+00],\n",
            "          [ 1.2069e+00, -6.6083e-01, -2.4182e+00,  ...,  1.7901e+00,\n",
            "           -1.0635e+00, -2.4927e-01],\n",
            "          [ 7.7709e-01,  8.8719e-01, -7.4836e-01,  ...,  3.6271e-01,\n",
            "            4.0510e-03, -6.0229e-01],\n",
            "          ...,\n",
            "          [ 7.5037e-01, -1.4964e+00,  6.7067e-02,  ..., -3.3906e-02,\n",
            "           -3.0412e+00, -1.1526e+00],\n",
            "          [ 2.4011e-01,  1.2370e+00, -2.4434e-01,  ..., -1.1051e+00,\n",
            "            9.1343e-01,  7.0917e-01],\n",
            "          [-2.9356e-01,  1.5114e+00, -1.1762e+00,  ..., -3.0314e-01,\n",
            "            1.0001e+00, -2.6587e-01]],\n",
            "\n",
            "         [[-4.3936e-01,  4.8301e-01, -3.0917e-01,  ...,  3.3958e-02,\n",
            "            1.6466e+00, -1.6042e+00],\n",
            "          [ 3.2083e-01,  5.2448e-01, -1.1964e-01,  ...,  1.9096e+00,\n",
            "            8.1464e-01, -2.8561e-02],\n",
            "          [-6.6556e-01,  6.2853e-01,  1.6135e+00,  ..., -9.5751e-01,\n",
            "            4.5857e-01,  1.2061e-01],\n",
            "          ...,\n",
            "          [ 6.6254e-01,  1.1132e+00,  5.4804e-01,  ...,  3.9170e-01,\n",
            "           -1.5065e-01, -4.1507e-01],\n",
            "          [ 9.7273e-03,  3.5142e-01, -8.2834e-01,  ..., -8.5267e-01,\n",
            "            4.2567e-01, -9.6744e-01],\n",
            "          [ 5.3187e-01, -1.1069e-01,  2.2216e-01,  ..., -2.5183e+00,\n",
            "            5.5064e-01,  1.2019e+00]],\n",
            "\n",
            "         [[-7.5083e-02,  9.2809e-01, -1.3135e+00,  ..., -6.7457e-01,\n",
            "           -5.9190e-01,  1.7074e-01],\n",
            "          [-1.2229e+00,  1.0734e+00,  4.5124e-01,  ..., -1.4905e+00,\n",
            "            9.0587e-01, -1.6985e+00],\n",
            "          [-7.3907e-01,  6.2465e-01,  9.4574e-01,  ...,  1.2407e+00,\n",
            "           -1.9295e+00, -3.5009e-01],\n",
            "          ...,\n",
            "          [-4.9605e-01,  1.3640e+00,  9.4293e-01,  ...,  6.7615e-01,\n",
            "           -6.5612e-01, -9.9023e-01],\n",
            "          [ 3.1991e-02, -1.8353e+00, -5.4671e-01,  ...,  1.9373e+00,\n",
            "           -1.3483e+00,  9.1022e-01],\n",
            "          [ 2.6003e-01, -5.0406e-01,  1.0229e+00,  ...,  3.9919e-01,\n",
            "           -2.5116e-01,  7.2331e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1716e-01, -7.9117e-01,  2.6882e-01,  ..., -1.4115e+00,\n",
            "            4.5774e-01, -5.0755e-01],\n",
            "          [-1.0301e-01, -7.5369e-01, -6.9513e-02,  ...,  9.4203e-01,\n",
            "           -6.6069e-01, -5.9594e-01],\n",
            "          [ 8.3937e-01,  9.0309e-02, -1.4629e+00,  ..., -6.8194e-01,\n",
            "           -1.8963e-01,  8.2883e-01],\n",
            "          ...,\n",
            "          [-2.9220e-01,  1.3460e-01, -2.0366e+00,  ...,  1.2013e+00,\n",
            "           -4.9486e-01,  1.4670e+00],\n",
            "          [-1.9677e+00, -7.5486e-01, -5.5304e-01,  ...,  1.0464e-01,\n",
            "           -1.5100e-01, -5.9713e-01],\n",
            "          [-2.9872e-02,  1.4122e+00,  1.4568e-01,  ..., -1.3708e-02,\n",
            "            1.2918e+00, -2.8493e-01]],\n",
            "\n",
            "         [[ 1.7484e+00, -1.1843e-02,  2.8603e-01,  ...,  4.5456e-01,\n",
            "            2.3098e+00,  1.1923e+00],\n",
            "          [-1.7516e+00, -7.8099e-02, -7.7982e-02,  ...,  1.3788e+00,\n",
            "           -9.4816e-01, -1.0883e+00],\n",
            "          [-1.0736e+00, -2.9645e-01,  6.1831e-02,  ..., -2.8710e-02,\n",
            "            7.2416e-01, -2.6891e-01],\n",
            "          ...,\n",
            "          [ 2.1072e+00,  5.5768e-02, -9.4066e-01,  ...,  2.9173e-01,\n",
            "           -9.6388e-02,  7.8542e-01],\n",
            "          [ 6.3113e-01,  6.2880e-01,  7.0085e-02,  ...,  1.2250e+00,\n",
            "            1.7781e+00,  1.5119e+00],\n",
            "          [ 2.5849e-01,  7.4308e-01, -4.7581e-01,  ...,  9.5532e-01,\n",
            "           -5.1490e-01, -2.2773e+00]],\n",
            "\n",
            "         [[ 1.9220e+00,  1.0968e-01,  2.6933e-01,  ..., -7.5068e-01,\n",
            "           -1.4814e+00,  3.6470e-01],\n",
            "          [ 5.6710e-01,  6.1784e-01,  9.0457e-01,  ..., -2.5811e-01,\n",
            "            5.3232e-01, -6.0924e-01],\n",
            "          [-9.4667e-01, -3.7336e-02, -3.7904e-01,  ...,  1.2884e+00,\n",
            "            2.2570e-01, -1.0533e+00],\n",
            "          ...,\n",
            "          [ 2.3756e+00,  5.2962e-01, -1.1011e-01,  ..., -7.0840e-01,\n",
            "           -1.7310e-01,  9.0390e-01],\n",
            "          [-1.0080e+00,  4.3848e-01,  9.9526e-01,  ..., -3.9822e-01,\n",
            "            1.7629e+00,  6.7495e-01],\n",
            "          [ 1.6064e+00, -5.5032e-01,  9.9806e-01,  ..., -3.1646e-01,\n",
            "            5.3314e-01,  4.5686e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.6301e-01,  5.6971e-01,  5.2414e-01,  ..., -1.9003e+00,\n",
            "            2.1182e-01, -2.4399e-01],\n",
            "          [ 3.9857e-01, -8.4112e-01,  3.0830e-01,  ...,  5.0797e-01,\n",
            "            3.4803e-01,  6.7189e-02],\n",
            "          [ 5.3888e-01, -7.2314e-01, -1.8856e+00,  ..., -5.1888e-01,\n",
            "           -1.6823e-01, -8.4517e-01],\n",
            "          ...,\n",
            "          [ 1.5854e-01,  1.2774e-01, -9.9445e-02,  ..., -1.3921e+00,\n",
            "            4.6026e-01, -8.9681e-01],\n",
            "          [-1.6308e+00, -1.0385e+00, -1.5168e+00,  ...,  2.2118e-01,\n",
            "           -7.3240e-01, -1.3575e+00],\n",
            "          [-1.1818e+00, -3.0523e-01, -5.0119e-02,  ..., -3.1953e-01,\n",
            "            1.9637e-02, -9.6400e-01]],\n",
            "\n",
            "         [[ 9.7564e-01,  6.1243e-01,  8.6475e-01,  ..., -1.1169e+00,\n",
            "           -9.4784e-01, -9.3093e-01],\n",
            "          [-4.5761e-01, -9.2824e-02, -7.1891e-01,  ...,  2.9980e-01,\n",
            "           -1.7500e+00,  6.5524e-01],\n",
            "          [ 5.4946e-02, -6.0599e-02, -1.9464e+00,  ...,  1.7091e+00,\n",
            "            1.9571e+00,  1.3035e-01],\n",
            "          ...,\n",
            "          [ 1.9199e+00, -5.2063e-01, -7.6887e-01,  ..., -7.5830e-01,\n",
            "           -6.7691e-01, -1.7760e+00],\n",
            "          [-4.8123e-01, -7.5449e-01, -5.8192e-01,  ..., -7.7932e-01,\n",
            "           -4.5710e-01,  6.5840e-02],\n",
            "          [-3.9750e-01,  7.4663e-01,  5.4769e-01,  ..., -2.5809e-01,\n",
            "           -9.9249e-01,  5.5346e-01]],\n",
            "\n",
            "         [[-5.1403e-01, -8.5414e-01,  1.7503e-01,  ...,  1.9745e+00,\n",
            "           -9.9809e-01, -1.3660e+00],\n",
            "          [ 8.3235e-01, -1.1845e+00,  2.5299e-01,  ..., -1.3133e+00,\n",
            "            2.1501e+00,  1.8234e+00],\n",
            "          [-2.0532e+00,  1.0675e+00,  1.9103e+00,  ...,  1.6820e+00,\n",
            "            7.3797e-01,  1.5296e+00],\n",
            "          ...,\n",
            "          [ 9.2857e-01, -1.3642e+00,  8.6697e-02,  ...,  1.7663e+00,\n",
            "            4.3366e-01, -1.8612e-01],\n",
            "          [-2.3624e-01, -4.7754e-01, -6.6514e-01,  ..., -3.5126e-01,\n",
            "            8.2053e-02, -1.4308e-01],\n",
            "          [ 9.1636e-01,  8.1581e-01, -9.1652e-01,  ..., -1.9471e+00,\n",
            "            1.4015e+00,  5.5305e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.7483e-01, -2.0574e+00,  5.9302e-02,  ..., -1.1339e+00,\n",
            "           -1.0314e+00, -8.9621e-01],\n",
            "          [-1.9649e+00, -4.4004e-01, -2.0020e+00,  ...,  6.4504e-01,\n",
            "           -4.2242e-01,  6.5081e-01],\n",
            "          [-1.0152e+00, -4.4643e-01, -1.0220e+00,  ...,  4.5435e-01,\n",
            "            4.6785e-01,  4.1736e-01],\n",
            "          ...,\n",
            "          [ 6.5583e-01, -6.8020e-01, -2.3150e-01,  ...,  3.8497e-01,\n",
            "           -4.6243e-01,  7.7659e-02],\n",
            "          [ 1.5243e+00,  4.7031e-01, -5.0464e-03,  ..., -5.4549e-01,\n",
            "           -5.8786e-01,  1.5814e+00],\n",
            "          [-3.7531e-01, -2.1980e-01,  3.6553e-01,  ..., -1.6368e-01,\n",
            "            7.0631e-01,  7.4951e-01]],\n",
            "\n",
            "         [[ 8.8414e-01,  4.2568e-01,  1.4175e-01,  ...,  1.3596e-02,\n",
            "           -4.7740e-01, -1.4876e+00],\n",
            "          [ 4.7521e-01, -1.8161e+00, -1.0747e+00,  ..., -1.7411e-01,\n",
            "           -1.0873e+00,  1.0169e-01],\n",
            "          [-8.3088e-01,  1.3866e+00, -1.0816e+00,  ...,  2.2047e+00,\n",
            "            1.7426e+00,  1.4662e+00],\n",
            "          ...,\n",
            "          [ 1.4436e-01, -1.6645e-01, -1.1023e+00,  ..., -1.2958e-01,\n",
            "           -1.7200e-01, -7.2952e-01],\n",
            "          [-2.2746e+00, -5.3517e-01, -9.7810e-01,  ..., -1.2964e+00,\n",
            "           -1.0562e+00, -1.4213e-01],\n",
            "          [-8.0979e-01,  1.4609e+00,  1.4025e+00,  ..., -1.6602e+00,\n",
            "           -4.8197e-01, -2.1041e-01]],\n",
            "\n",
            "         [[-3.4639e-01, -1.2803e+00, -8.4476e-01,  ...,  2.8567e-01,\n",
            "            4.3164e-01, -8.5184e-02],\n",
            "          [-6.2790e-01,  7.7894e-01,  7.8257e-01,  ...,  4.5900e-01,\n",
            "            1.2773e+00,  1.5658e-01],\n",
            "          [-6.7732e-01, -8.5251e-01, -7.6796e-01,  ..., -1.2334e-01,\n",
            "            1.5839e+00,  9.4245e-01],\n",
            "          ...,\n",
            "          [-1.0201e-01,  4.3231e-01,  8.7912e-01,  ..., -1.3337e-01,\n",
            "           -1.8291e+00, -4.2776e-01],\n",
            "          [ 1.5002e+00,  6.4150e-01,  4.4063e-01,  ..., -8.6751e-02,\n",
            "           -7.7338e-01, -1.8916e-02],\n",
            "          [-3.9775e-01,  1.9656e+00, -4.7384e-01,  ...,  1.4878e+00,\n",
            "            7.4443e-02,  5.7325e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3831e-01,  4.7993e-01,  5.5122e-01,  ..., -1.2764e+00,\n",
            "            6.0198e-01, -2.5465e-01],\n",
            "          [-8.6976e-01, -9.0415e-01, -1.3082e+00,  ..., -1.2887e+00,\n",
            "            5.5837e-01,  8.3653e-01],\n",
            "          [-2.1294e-03, -5.7642e-01,  3.7473e-01,  ..., -2.7524e-01,\n",
            "            1.8344e-01, -9.6687e-01],\n",
            "          ...,\n",
            "          [ 1.4988e+00,  1.7127e+00, -1.2468e+00,  ...,  8.7550e-02,\n",
            "           -4.3793e-01,  1.4528e+00],\n",
            "          [ 1.5341e-01, -9.3553e-02,  1.7721e+00,  ..., -9.4362e-01,\n",
            "           -2.4013e+00, -4.5604e-01],\n",
            "          [ 2.9417e-02,  1.7196e+00, -1.3833e+00,  ...,  1.9290e+00,\n",
            "           -7.1795e-01,  1.4755e+00]],\n",
            "\n",
            "         [[-1.5632e+00, -3.0713e-01, -4.9537e-01,  ..., -7.1675e-01,\n",
            "           -1.6395e-01,  1.7612e+00],\n",
            "          [ 8.1558e-01,  1.7352e+00, -5.1639e-01,  ...,  3.3476e-01,\n",
            "            3.9214e-01, -7.8796e-01],\n",
            "          [ 8.0331e-01, -4.7636e-01,  7.8249e-01,  ...,  6.0089e-01,\n",
            "            4.1766e-01,  1.4081e+00],\n",
            "          ...,\n",
            "          [-1.8057e-01, -3.2700e-01,  9.8891e-01,  ...,  3.7979e-02,\n",
            "           -1.5483e-01,  1.7645e-01],\n",
            "          [-3.3570e-02,  2.2780e-01, -1.4691e+00,  ..., -1.7204e-01,\n",
            "            3.5154e-01, -3.8119e-02],\n",
            "          [ 1.1369e-01,  3.0314e-02, -8.5576e-01,  ..., -1.0885e+00,\n",
            "            4.9050e-01, -1.5516e+00]],\n",
            "\n",
            "         [[ 1.9191e+00,  1.9405e-01, -1.1416e+00,  ...,  1.0188e+00,\n",
            "           -4.7492e-01,  9.2062e-01],\n",
            "          [ 1.6487e+00, -1.6399e-01,  9.4663e-01,  ...,  5.8992e-01,\n",
            "           -1.0420e+00, -1.1473e+00],\n",
            "          [-1.8246e+00, -1.5465e-01,  1.6600e+00,  ..., -4.2719e-01,\n",
            "            2.4693e-01,  1.4253e+00],\n",
            "          ...,\n",
            "          [ 4.5633e-01,  8.3888e-01, -2.1445e+00,  ...,  1.1091e+00,\n",
            "            1.6493e-01,  6.3217e-01],\n",
            "          [ 1.1412e+00, -6.9377e-01, -9.8651e-02,  ...,  8.6815e-02,\n",
            "            1.7270e+00,  1.6229e+00],\n",
            "          [ 9.8925e-01,  9.2062e-01,  6.9313e-03,  ...,  2.3731e-01,\n",
            "           -8.1917e-01,  1.6266e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4435e+00, -4.2079e-01, -1.7031e+00,  ...,  1.8727e+00,\n",
            "            3.9263e-01, -8.3915e-02],\n",
            "          [-1.9423e+00, -3.6525e-01,  4.9572e-01,  ..., -4.2817e-02,\n",
            "            1.1365e+00,  3.5542e-01],\n",
            "          [-4.5684e-01, -6.0057e-01, -1.3940e+00,  ..., -1.9990e+00,\n",
            "           -1.6042e+00,  2.3558e+00],\n",
            "          ...,\n",
            "          [ 8.2891e-02, -6.5565e-01,  1.5107e-01,  ...,  1.4347e+00,\n",
            "           -1.3295e-01, -2.5230e-01],\n",
            "          [ 5.4517e-01,  8.3401e-01,  3.6395e-01,  ..., -3.9400e-01,\n",
            "            1.1065e+00,  1.3046e+00],\n",
            "          [-7.7605e-01,  2.1401e-02,  6.4191e-01,  ..., -1.2743e+00,\n",
            "           -2.0922e-01, -1.3478e+00]],\n",
            "\n",
            "         [[ 6.7902e-01, -1.6375e+00,  7.3134e-01,  ..., -2.3338e+00,\n",
            "            5.5778e-01,  2.0265e-01],\n",
            "          [ 2.3440e-01,  8.1140e-01,  1.5435e+00,  ...,  7.6085e-01,\n",
            "           -3.7485e-01, -6.3582e-02],\n",
            "          [-2.5805e-01, -1.1527e+00, -5.7645e-01,  ...,  3.2473e-01,\n",
            "            4.2708e-01,  9.8398e-01],\n",
            "          ...,\n",
            "          [ 9.2290e-01,  4.1861e-01,  1.0719e-01,  ...,  1.6662e+00,\n",
            "            1.1709e+00,  4.5961e-01],\n",
            "          [-2.6429e-01, -6.7647e-03,  1.0463e-01,  ...,  9.0011e-01,\n",
            "            6.3376e-01, -4.9741e-01],\n",
            "          [ 7.7087e-01, -3.9175e-01, -3.0129e-01,  ..., -2.6621e-01,\n",
            "           -1.0339e+00,  1.2429e+00]],\n",
            "\n",
            "         [[-1.4963e+00, -1.5700e-01,  1.2091e+00,  ...,  5.3711e-01,\n",
            "            1.2431e+00,  1.8097e+00],\n",
            "          [-7.2316e-01, -1.1002e+00, -8.8497e-01,  ..., -7.2996e-02,\n",
            "           -3.6056e-01, -1.1857e+00],\n",
            "          [-7.6613e-01,  2.7098e-01,  1.8741e+00,  ...,  5.1444e-01,\n",
            "            3.7649e-01, -9.3433e-01],\n",
            "          ...,\n",
            "          [-1.3605e+00, -4.4851e-01, -1.5715e+00,  ...,  5.8111e-01,\n",
            "           -5.1066e-01, -1.8652e-01],\n",
            "          [-9.1444e-01,  2.0707e+00,  1.5337e+00,  ..., -1.4674e+00,\n",
            "           -1.0802e+00,  2.2876e+00],\n",
            "          [ 1.5314e+00,  2.3073e-01,  2.4146e+00,  ...,  1.3258e+00,\n",
            "            1.1938e-01,  5.5966e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1774e-01,  7.9678e-01, -9.4825e-01,  ..., -1.0421e-02,\n",
            "            9.4116e-01,  4.1381e-01],\n",
            "          [ 3.6122e-01,  1.2734e+00, -6.0931e-01,  ..., -6.8286e-01,\n",
            "            1.0320e+00, -8.3686e-01],\n",
            "          [ 1.3941e+00, -1.5144e+00,  1.7755e-01,  ...,  8.9184e-01,\n",
            "            8.6937e-02, -1.0884e-01],\n",
            "          ...,\n",
            "          [-3.4729e-01,  2.4289e-01,  1.1456e-01,  ..., -1.4048e+00,\n",
            "            9.9389e-01,  1.4928e+00],\n",
            "          [-3.2664e-01,  1.0078e+00, -2.9228e-01,  ...,  1.4007e+00,\n",
            "            1.9225e+00,  2.4103e-01],\n",
            "          [-7.0118e-01, -1.0420e-01,  8.1510e-01,  ...,  1.4853e-01,\n",
            "            1.1079e+00, -4.6023e-01]],\n",
            "\n",
            "         [[-5.6265e-02,  2.7240e-01,  2.5722e-01,  ..., -1.2927e+00,\n",
            "           -1.5235e-01,  1.1044e+00],\n",
            "          [ 6.5815e-01,  4.3481e-01,  9.3374e-01,  ..., -1.1868e+00,\n",
            "            2.2182e-02, -7.3273e-02],\n",
            "          [-3.3983e-01, -1.4886e+00, -4.0095e-02,  ...,  2.2884e-01,\n",
            "            9.9024e-01,  1.0981e-01],\n",
            "          ...,\n",
            "          [-6.8173e-01, -1.9981e-01, -4.2761e-01,  ..., -9.3304e-02,\n",
            "            1.0903e+00, -1.1134e+00],\n",
            "          [-8.1651e-01,  1.6739e-01, -6.3574e-01,  ...,  8.6214e-01,\n",
            "           -1.6812e+00, -6.6103e-01],\n",
            "          [ 1.1538e+00, -2.8553e-01, -9.0266e-01,  ...,  3.7141e-01,\n",
            "            2.3518e-01,  9.1017e-01]],\n",
            "\n",
            "         [[-2.8197e+00,  6.5381e-01, -4.1788e-01,  ...,  3.8123e-01,\n",
            "           -9.0670e-01,  1.5990e+00],\n",
            "          [-8.4350e-01, -1.5189e+00,  1.2512e+00,  ...,  1.2823e-01,\n",
            "            8.2186e-01,  6.3655e-01],\n",
            "          [-7.2232e-01, -5.3907e-01,  1.3215e+00,  ...,  1.1477e+00,\n",
            "           -7.9489e-01, -1.7528e+00],\n",
            "          ...,\n",
            "          [-7.2054e-01,  8.5851e-02,  1.1992e+00,  ..., -7.6157e-02,\n",
            "            1.3024e+00, -7.3101e-01],\n",
            "          [ 9.0586e-01, -1.7599e+00, -9.6037e-01,  ...,  4.7680e-01,\n",
            "           -5.4873e-01, -3.0098e-01],\n",
            "          [ 2.0401e-01, -7.9122e-01, -2.1163e+00,  ...,  1.0036e+00,\n",
            "            8.6843e-02,  8.6278e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3105e+00, -1.2266e-01,  2.3136e+00,  ...,  1.4263e-01,\n",
            "           -1.2864e-01, -6.5746e-01],\n",
            "          [ 3.6203e-01, -1.0997e+00,  1.9642e+00,  ..., -3.9849e-02,\n",
            "            1.8746e+00,  4.3777e-01],\n",
            "          [ 5.5757e-01,  2.0096e+00,  4.8495e-01,  ..., -1.2521e+00,\n",
            "           -8.3198e-02,  8.6840e-01],\n",
            "          ...,\n",
            "          [-1.4779e-01, -1.0497e+00, -7.0877e-01,  ...,  6.6811e-01,\n",
            "            6.0191e-01,  3.6918e-01],\n",
            "          [-1.0738e+00,  5.3191e-01, -1.2374e-02,  ...,  8.8326e-01,\n",
            "            9.3085e-02,  3.1224e-01],\n",
            "          [ 7.9506e-01,  1.7297e+00,  4.2067e-01,  ...,  1.7877e-02,\n",
            "            3.1174e-02, -8.1770e-01]],\n",
            "\n",
            "         [[-3.4826e+00, -1.5952e+00, -1.8922e+00,  ..., -1.5898e+00,\n",
            "            9.5515e-02, -4.3183e-01],\n",
            "          [-7.5363e-01,  4.5031e-01,  1.5209e+00,  ..., -1.1390e+00,\n",
            "            2.2558e-01, -7.1048e-01],\n",
            "          [-1.6176e+00, -1.4766e-01, -1.6038e+00,  ..., -5.4774e-01,\n",
            "           -1.1332e+00, -3.3457e-01],\n",
            "          ...,\n",
            "          [ 8.5904e-01,  5.7823e-01,  5.1483e-01,  ...,  2.5287e-01,\n",
            "           -1.2206e+00, -1.7309e-01],\n",
            "          [-1.0236e-02,  5.5008e-02,  8.4142e-01,  ..., -5.8484e-01,\n",
            "           -5.0831e-01, -1.5389e+00],\n",
            "          [ 1.4461e+00, -8.3042e-01,  7.4536e-01,  ...,  2.4031e-01,\n",
            "           -4.6640e-01,  4.1180e-01]],\n",
            "\n",
            "         [[ 1.0836e+00,  1.0913e-01,  7.4514e-02,  ..., -4.3259e-01,\n",
            "           -7.2189e-01,  4.3890e-01],\n",
            "          [ 9.8312e-01,  1.2686e+00,  6.2398e-01,  ...,  2.0977e-01,\n",
            "            2.4394e+00, -5.5219e-02],\n",
            "          [ 8.1442e-01, -9.5484e-01,  2.0340e+00,  ...,  7.3233e-01,\n",
            "           -4.6963e-01,  1.1004e-01],\n",
            "          ...,\n",
            "          [ 1.1755e+00,  1.6271e-01, -1.4811e+00,  ..., -4.6277e-01,\n",
            "           -1.6019e+00, -9.3909e-01],\n",
            "          [-1.2327e+00, -1.3061e+00, -1.2240e+00,  ...,  1.4264e+00,\n",
            "           -5.7985e-01,  1.6512e+00],\n",
            "          [-6.3972e-01,  1.4632e+00,  6.6514e-01,  ..., -1.7846e+00,\n",
            "           -1.2182e-01, -4.5752e-01]]]])\n",
            "tensor([[[[ 1.1518e-01,  9.4224e-02,  6.1798e-01,  ..., -2.0834e-01,\n",
            "           -3.9306e-01,  4.7031e-02],\n",
            "          [-8.5200e-01, -2.0309e-01, -1.0453e+00,  ...,  5.6584e-01,\n",
            "            9.7154e-02,  3.5512e-02],\n",
            "          [-2.7461e-01, -5.4183e-01, -6.1613e-01,  ..., -9.4223e-01,\n",
            "           -3.6958e-01,  1.0454e+00],\n",
            "          ...,\n",
            "          [-2.8181e-01,  5.2055e-02,  3.8257e-02,  ..., -6.2468e-01,\n",
            "            1.1956e+00, -4.4877e-01],\n",
            "          [-6.2490e-02,  1.8813e-01,  8.6578e-01,  ..., -2.4359e-01,\n",
            "            1.8170e-02,  1.9571e-01],\n",
            "          [ 1.1512e-01,  2.7538e-01, -3.1998e-01,  ..., -9.3595e-01,\n",
            "           -4.4332e-01, -1.8130e-03]],\n",
            "\n",
            "         [[ 1.5417e-01, -3.9336e-02, -6.1687e-01,  ..., -1.6019e-01,\n",
            "            2.1344e-02,  9.4699e-03],\n",
            "          [ 2.9682e-01,  3.2625e-01,  5.3675e-01,  ...,  1.1728e-02,\n",
            "           -2.1267e-01, -5.6977e-01],\n",
            "          [-3.6546e-01, -5.1420e-01,  9.7762e-02,  ..., -4.7195e-01,\n",
            "           -5.0702e-01, -2.2123e-01],\n",
            "          ...,\n",
            "          [-4.1626e-01, -6.7215e-01, -6.2995e-01,  ...,  1.7506e-01,\n",
            "            1.6065e-01, -1.7376e-01],\n",
            "          [-6.4066e-01, -3.7198e-01, -2.2211e-01,  ..., -3.1802e-01,\n",
            "           -9.0907e-02,  1.0429e-02],\n",
            "          [-4.1937e-01, -6.3951e-01, -4.6692e-01,  ...,  2.4587e-01,\n",
            "           -4.8032e-01, -5.8429e-02]],\n",
            "\n",
            "         [[ 8.1731e-02,  6.1184e-02,  5.7823e-01,  ...,  6.8603e-02,\n",
            "            3.3398e-01, -2.5500e-01],\n",
            "          [ 6.1863e-01,  4.6707e-01, -3.6863e-01,  ..., -2.7432e-01,\n",
            "           -5.2408e-02, -6.4216e-01],\n",
            "          [-6.9701e-01,  1.9920e-01, -1.1302e+00,  ..., -7.7194e-01,\n",
            "           -4.5733e-01,  5.5092e-02],\n",
            "          ...,\n",
            "          [ 4.6176e-01,  5.4157e-01,  8.0421e-02,  ...,  2.6282e-01,\n",
            "            8.3975e-02,  9.9617e-02],\n",
            "          [ 7.5344e-01,  4.7148e-02, -9.5264e-03,  ..., -5.6121e-01,\n",
            "            2.2502e-02,  2.1478e-01],\n",
            "          [-4.0710e-01, -6.0631e-02,  1.0397e-01,  ..., -4.1616e-01,\n",
            "           -1.6486e-01, -4.6331e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8064e-01,  2.9177e-01,  6.9125e-01,  ..., -1.3120e-02,\n",
            "           -4.2052e-01, -3.1313e-01],\n",
            "          [-1.8630e-02,  9.2230e-01, -6.2252e-01,  ..., -5.4394e-01,\n",
            "           -1.3309e-01,  1.3548e-01],\n",
            "          [ 3.7798e-01, -6.2421e-01,  2.8704e-01,  ..., -1.0818e+00,\n",
            "           -1.5529e-01,  4.6868e-02],\n",
            "          ...,\n",
            "          [-3.4839e-01,  9.9252e-02, -3.0925e-01,  ..., -9.0165e-01,\n",
            "            2.6381e-01, -7.0896e-01],\n",
            "          [-1.5829e-01, -7.8394e-02,  9.2081e-01,  ...,  4.2460e-02,\n",
            "           -3.8151e-01, -2.8186e-01],\n",
            "          [-6.1704e-02, -4.0486e-01, -3.8522e-01,  ...,  9.4936e-02,\n",
            "           -4.3393e-01,  2.1963e-01]],\n",
            "\n",
            "         [[-1.9262e-04, -9.4428e-02,  7.1301e-02,  ..., -8.7973e-01,\n",
            "            1.7347e-01, -7.8926e-02],\n",
            "          [-2.2708e-01, -8.6584e-01, -3.1520e-01,  ..., -4.5427e-01,\n",
            "           -1.3000e-01,  3.7363e-01],\n",
            "          [-4.0285e-01,  5.9176e-01, -8.4133e-02,  ..., -9.1231e-02,\n",
            "            5.9652e-01, -3.8700e-01],\n",
            "          ...,\n",
            "          [ 6.1875e-01,  2.0424e-02,  9.8615e-01,  ..., -4.4360e-01,\n",
            "            8.9545e-01, -2.8039e-01],\n",
            "          [-4.3801e-01,  3.0481e-01, -2.0976e-01,  ..., -6.0404e-02,\n",
            "            5.9346e-01, -2.4950e-01],\n",
            "          [-3.6788e-01, -2.4462e-01,  1.0671e+00,  ...,  6.5856e-01,\n",
            "           -3.0537e-02, -3.2462e-01]],\n",
            "\n",
            "         [[ 1.4520e-01,  2.8035e-01,  2.0463e-01,  ...,  1.8405e-01,\n",
            "            1.4397e-01, -1.6942e-01],\n",
            "          [-6.2409e-01,  3.5515e-01,  5.1393e-01,  ..., -8.8427e-01,\n",
            "           -2.0224e-01, -7.4598e-01],\n",
            "          [-2.4244e-01, -9.1735e-01, -1.1463e+00,  ..., -9.4961e-02,\n",
            "            3.7884e-01,  8.5971e-01],\n",
            "          ...,\n",
            "          [-6.9765e-02,  3.3745e-02,  2.7757e-01,  ...,  5.1704e-01,\n",
            "            3.4533e-01,  7.5803e-01],\n",
            "          [ 1.2795e-01, -4.4530e-01,  4.9135e-01,  ..., -6.6635e-01,\n",
            "           -5.1619e-02, -5.4984e-02],\n",
            "          [-1.8662e-02,  4.6528e-01,  5.4106e-02,  ...,  8.1841e-01,\n",
            "            1.1092e-01, -1.0271e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2670e-01,  2.9507e-01, -2.4035e-01,  ...,  1.4572e-01,\n",
            "           -6.7708e-02, -2.0718e-01],\n",
            "          [ 5.0416e-02,  4.0517e-01,  2.3787e-01,  ...,  6.6112e-01,\n",
            "            7.1143e-01,  4.0911e-02],\n",
            "          [ 2.2184e-01,  4.3391e-01, -3.9164e-03,  ...,  1.0155e+00,\n",
            "            8.7175e-01,  1.8411e-01],\n",
            "          ...,\n",
            "          [-4.1494e-01, -2.7636e-01, -5.7559e-02,  ..., -5.8966e-01,\n",
            "            2.0425e-01,  2.5180e-01],\n",
            "          [ 5.0180e-02,  1.3007e-01, -3.5159e-01,  ...,  1.8605e-01,\n",
            "            6.7832e-01, -5.2811e-01],\n",
            "          [-1.3790e-01, -6.8703e-01,  4.9228e-01,  ...,  1.3664e+00,\n",
            "            4.9268e-01, -2.1263e-01]],\n",
            "\n",
            "         [[-8.8941e-02, -1.7208e-01, -4.4010e-01,  ...,  2.9385e-01,\n",
            "           -7.5364e-02,  3.5416e-01],\n",
            "          [-1.2793e-01,  3.5301e-01,  3.2971e-01,  ..., -7.4723e-01,\n",
            "            2.6590e-01,  3.3439e-01],\n",
            "          [-8.4843e-02, -5.0890e-01, -1.7530e-01,  ...,  5.7486e-01,\n",
            "            7.6223e-02,  5.5124e-02],\n",
            "          ...,\n",
            "          [-2.7978e-01,  1.2450e-01, -1.0926e-01,  ..., -1.0704e+00,\n",
            "            5.4441e-01,  1.3834e-01],\n",
            "          [-6.5034e-02, -1.0673e-01, -5.8123e-01,  ...,  4.6700e-01,\n",
            "            9.4448e-01, -3.3179e-02],\n",
            "          [-6.0483e-01,  5.4838e-02,  1.2159e-01,  ..., -1.4753e-01,\n",
            "            7.4770e-01,  6.7948e-01]],\n",
            "\n",
            "         [[-4.3272e-01, -7.9514e-02,  1.7224e-03,  ..., -7.7619e-02,\n",
            "            2.7058e-01, -6.8541e-02],\n",
            "          [-5.4302e-01, -1.9784e-01, -6.5381e-01,  ..., -3.4768e-01,\n",
            "            6.5082e-02, -1.9884e-01],\n",
            "          [ 2.0387e-01, -5.3329e-01, -4.4265e-01,  ..., -3.1270e-01,\n",
            "           -1.0477e+00,  2.3752e-01],\n",
            "          ...,\n",
            "          [-4.1309e-01, -4.4779e-01, -6.2154e-01,  ..., -9.4250e-01,\n",
            "            1.6574e-01, -7.5889e-01],\n",
            "          [ 3.6095e-02, -5.2962e-01,  2.3342e-02,  ..., -1.5082e-01,\n",
            "           -4.2585e-01,  4.5682e-01],\n",
            "          [ 2.0959e-01,  2.4990e-01, -8.5362e-01,  ..., -2.0902e-01,\n",
            "            2.7169e-01, -8.2493e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0466e-01, -3.6221e-01, -5.3063e-01,  ...,  4.5655e-01,\n",
            "           -2.1757e-01, -5.6114e-01],\n",
            "          [-4.4725e-01, -1.2638e-01,  8.2200e-01,  ...,  1.3379e-02,\n",
            "           -2.4040e-01, -3.4418e-01],\n",
            "          [ 1.6113e-01,  3.6045e-01, -5.0115e-01,  ...,  2.0333e-01,\n",
            "           -3.3228e-01, -2.9027e-01],\n",
            "          ...,\n",
            "          [-4.2946e-01,  7.9153e-02, -7.6461e-01,  ...,  5.5767e-01,\n",
            "            5.1016e-01,  1.0373e-01],\n",
            "          [-1.7330e-01, -4.9180e-01,  1.4889e-01,  ..., -3.1063e-01,\n",
            "            1.2170e-02, -1.3825e-01],\n",
            "          [ 4.6520e-01,  2.0367e-01,  3.9974e-01,  ..., -9.9262e-02,\n",
            "            1.2731e-02, -2.8637e-01]],\n",
            "\n",
            "         [[-2.6649e-03,  2.4417e-01,  2.6533e-02,  ..., -2.1804e-01,\n",
            "           -2.1383e-01, -1.2382e-02],\n",
            "          [ 4.3194e-01, -7.1903e-01, -3.0124e-02,  ...,  1.2790e+00,\n",
            "           -2.8475e-01, -3.7845e-01],\n",
            "          [-4.1859e-01, -9.7392e-01,  4.2596e-01,  ..., -1.4388e-01,\n",
            "            1.0238e-01,  3.0406e-02],\n",
            "          ...,\n",
            "          [ 6.6613e-01, -5.8790e-01, -4.7241e-01,  ..., -1.2737e-01,\n",
            "           -5.5777e-01, -6.7512e-01],\n",
            "          [ 5.5251e-02, -3.7409e-01,  1.3764e+00,  ...,  4.3055e-01,\n",
            "           -8.9306e-02, -4.5752e-01],\n",
            "          [ 5.4201e-01, -8.5165e-02, -4.7246e-01,  ...,  6.5104e-02,\n",
            "           -8.8777e-02, -2.7338e-01]],\n",
            "\n",
            "         [[ 1.1443e-03, -2.4346e-01,  3.2083e-01,  ...,  5.5718e-01,\n",
            "            3.1135e-01, -1.0287e-02],\n",
            "          [ 3.9433e-01,  1.6563e-01,  1.2351e+00,  ..., -2.7888e-01,\n",
            "            6.3690e-01, -2.3003e-01],\n",
            "          [-4.5396e-02,  4.3673e-01, -1.8057e-01,  ...,  9.5061e-01,\n",
            "           -2.9964e-01,  5.7464e-01],\n",
            "          ...,\n",
            "          [ 5.7750e-01,  1.1518e-01, -1.6746e-01,  ...,  2.8064e-01,\n",
            "            6.2006e-01, -6.1548e-02],\n",
            "          [ 4.3973e-01,  2.0701e-02,  1.2503e-02,  ...,  1.6462e-01,\n",
            "           -6.3514e-01, -9.0845e-03],\n",
            "          [ 2.0135e-01,  4.1690e-01,  2.1797e-01,  ...,  6.1391e-01,\n",
            "            6.7161e-01, -2.8671e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.3648e-01,  1.7561e-01, -2.6167e-01,  ...,  2.6239e-01,\n",
            "           -6.4605e-02,  2.6680e-01],\n",
            "          [ 4.3046e-01,  1.6465e-01,  8.3780e-01,  ...,  1.7752e-01,\n",
            "           -2.6330e-01,  5.6588e-01],\n",
            "          [ 6.4594e-01, -3.8667e-01,  1.6619e+00,  ...,  3.1448e-01,\n",
            "            6.9286e-01, -4.2250e-01],\n",
            "          ...,\n",
            "          [ 4.6695e-01,  6.4269e-01,  1.7574e-01,  ..., -1.5445e-01,\n",
            "            7.1031e-01, -3.5181e-01],\n",
            "          [ 1.7295e-01, -3.6913e-01,  7.9201e-02,  ..., -6.9070e-01,\n",
            "            7.1902e-01,  4.7219e-01],\n",
            "          [ 1.5929e-02,  4.7418e-01,  5.8622e-01,  ..., -2.2108e-01,\n",
            "            3.3434e-02, -3.8361e-03]],\n",
            "\n",
            "         [[-8.6965e-02,  8.5242e-02,  6.0629e-01,  ...,  5.4322e-01,\n",
            "            2.2585e-01,  5.3380e-01],\n",
            "          [-2.3185e-02, -2.6492e-01, -8.1773e-01,  ...,  2.0460e-01,\n",
            "            7.5952e-01,  1.3115e-01],\n",
            "          [-1.0607e-01, -5.6439e-01, -8.9370e-01,  ...,  7.8686e-01,\n",
            "            2.0085e-02,  4.8487e-01],\n",
            "          ...,\n",
            "          [ 4.6339e-02, -3.6298e-02, -1.5215e-01,  ..., -3.0234e-01,\n",
            "            4.4591e-01,  8.2475e-02],\n",
            "          [-3.4567e-01, -2.2080e-01,  4.5595e-01,  ...,  3.9990e-02,\n",
            "            4.5641e-01,  4.1169e-01],\n",
            "          [-3.3835e-01, -4.9192e-01, -2.0604e-01,  ..., -7.4234e-02,\n",
            "            6.5384e-02, -2.7103e-01]],\n",
            "\n",
            "         [[-8.3983e-02,  2.6429e-02, -2.9207e-01,  ..., -1.4104e-02,\n",
            "           -4.3198e-01, -1.3596e-01],\n",
            "          [ 3.3609e-01, -4.8791e-01,  5.6512e-01,  ...,  4.9920e-02,\n",
            "           -2.4711e-01, -3.7089e-01],\n",
            "          [ 1.9619e-01,  4.6175e-01, -5.7129e-01,  ...,  8.7221e-02,\n",
            "           -9.7399e-01, -1.0499e-01],\n",
            "          ...,\n",
            "          [ 2.8775e-01,  3.5013e-01,  3.6251e-01,  ..., -4.0477e-01,\n",
            "           -1.1784e+00, -2.7791e-01],\n",
            "          [ 3.0531e-01,  2.0191e-01,  6.5688e-01,  ..., -3.5435e-01,\n",
            "           -8.7610e-01, -3.6776e-02],\n",
            "          [ 1.1825e-01, -6.2206e-01,  4.2452e-01,  ..., -5.2821e-01,\n",
            "           -1.8662e-01,  2.7384e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.4873e-01, -1.5109e-01, -7.1394e-02,  ..., -3.4945e-01,\n",
            "           -1.8187e-02,  1.0876e-01],\n",
            "          [ 6.3227e-02,  2.4801e-01, -4.9117e-03,  ..., -2.8953e-01,\n",
            "           -6.6071e-01, -6.2288e-02],\n",
            "          [-8.2504e-01, -8.8701e-03,  8.0553e-01,  ...,  3.1924e-01,\n",
            "           -2.4613e-01, -1.3855e-01],\n",
            "          ...,\n",
            "          [-3.0962e-01, -1.4965e-01, -2.4957e-01,  ...,  3.2001e-01,\n",
            "           -3.1751e-01, -2.6834e-01],\n",
            "          [-3.0588e-01, -1.0120e-01,  3.0539e-01,  ..., -6.9406e-01,\n",
            "           -2.6064e-01, -6.5008e-01],\n",
            "          [-2.6426e-01, -4.7565e-01, -9.7874e-02,  ..., -8.2417e-01,\n",
            "           -2.4574e-01,  6.9416e-02]],\n",
            "\n",
            "         [[ 2.0837e-01, -5.1575e-01,  3.4400e-01,  ...,  5.0626e-02,\n",
            "           -2.8625e-01, -2.1334e-01],\n",
            "          [ 2.6318e-01, -1.1573e-01,  1.8104e-01,  ...,  2.9045e-01,\n",
            "           -3.3671e-01, -2.8431e-02],\n",
            "          [ 7.4142e-01,  3.1483e-02, -1.9766e-01,  ..., -2.7143e-01,\n",
            "            6.7520e-02,  4.6007e-01],\n",
            "          ...,\n",
            "          [ 1.1482e-01, -9.8923e-03, -1.0568e+00,  ..., -3.8674e-02,\n",
            "           -3.1784e-01,  7.5562e-02],\n",
            "          [ 6.2027e-01, -1.9006e-01, -6.2104e-01,  ...,  7.7942e-03,\n",
            "           -3.2109e-01,  4.3511e-02],\n",
            "          [-1.7849e-01,  3.0835e-01, -6.6428e-01,  ..., -1.3337e-01,\n",
            "           -4.6776e-01,  5.1503e-01]],\n",
            "\n",
            "         [[-9.9023e-03,  1.5601e-01,  9.3556e-02,  ..., -7.0635e-01,\n",
            "            3.2731e-02,  3.2049e-01],\n",
            "          [ 5.2410e-02,  3.4089e-01,  4.9207e-01,  ...,  3.1296e-02,\n",
            "            1.4593e-01,  1.0814e-03],\n",
            "          [-1.2369e-01,  3.1763e-01,  5.9975e-01,  ...,  1.2873e-01,\n",
            "           -4.9549e-01, -1.1547e+00],\n",
            "          ...,\n",
            "          [-5.1943e-02, -1.2066e-01, -3.3327e-01,  ...,  1.0520e+00,\n",
            "           -3.6997e-01,  3.5227e-01],\n",
            "          [-6.8062e-01,  1.6121e-01,  2.4936e-01,  ..., -3.6071e-01,\n",
            "           -6.4682e-01,  5.3574e-01],\n",
            "          [-3.0054e-01, -3.2383e-01,  5.3480e-01,  ..., -1.8518e-01,\n",
            "            2.6698e-01, -1.6393e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8384e-01,  2.5767e-01,  5.5808e-01,  ...,  9.9473e-02,\n",
            "            5.6752e-01,  3.7290e-01],\n",
            "          [-5.0401e-01, -5.2114e-01, -6.4524e-01,  ...,  3.8614e-01,\n",
            "           -4.2217e-01,  5.5940e-01],\n",
            "          [ 4.8122e-01,  3.0417e-01,  4.6556e-02,  ...,  2.9968e-01,\n",
            "            3.3701e-01,  1.9025e-02],\n",
            "          ...,\n",
            "          [ 1.3539e-01, -5.6969e-01, -1.7323e-01,  ..., -2.3267e-01,\n",
            "            5.0794e-01, -7.7223e-02],\n",
            "          [ 1.4563e-01,  8.7599e-01,  3.1046e-01,  ..., -7.7448e-01,\n",
            "            2.4375e-01,  4.6955e-02],\n",
            "          [ 2.9799e-01,  4.4548e-01, -5.7306e-01,  ..., -2.8661e-02,\n",
            "           -6.5523e-01, -2.0947e-01]],\n",
            "\n",
            "         [[-5.0028e-01,  4.4148e-01, -2.7315e-01,  ...,  1.2153e-01,\n",
            "           -3.0307e-02,  2.3156e-01],\n",
            "          [ 2.6422e-01,  2.4621e-01, -3.5606e-01,  ...,  7.7573e-02,\n",
            "            2.7796e-02,  1.0307e-01],\n",
            "          [ 1.4026e-01, -6.8617e-01, -3.6508e-01,  ..., -1.7971e-02,\n",
            "            1.9443e-01,  1.6540e-02],\n",
            "          ...,\n",
            "          [ 6.4612e-02,  1.9696e-01,  2.4169e-01,  ..., -4.8186e-01,\n",
            "           -2.9226e-01, -3.7498e-02],\n",
            "          [-5.2739e-01,  1.2241e-01,  3.4153e-01,  ..., -1.6659e-01,\n",
            "            6.2151e-01, -1.4927e-01],\n",
            "          [-2.5940e-01, -8.1043e-02,  7.0663e-01,  ...,  1.0841e+00,\n",
            "            1.1790e+00,  4.8948e-01]],\n",
            "\n",
            "         [[-1.5256e-02, -1.7593e-01, -3.1397e-01,  ..., -6.4436e-02,\n",
            "           -5.5297e-01,  4.2271e-02],\n",
            "          [ 2.9874e-01, -7.7082e-01,  1.0816e-01,  ..., -4.4860e-01,\n",
            "           -7.7172e-02,  4.5050e-01],\n",
            "          [-7.3960e-01,  6.4011e-01, -3.4171e-01,  ...,  9.1312e-01,\n",
            "           -1.3954e-02,  5.6867e-01],\n",
            "          ...,\n",
            "          [-6.0169e-04, -1.9699e-01,  1.0485e+00,  ...,  2.2815e-01,\n",
            "            2.0619e-01,  8.8367e-01],\n",
            "          [-4.0739e-01, -6.2031e-01, -5.1621e-01,  ..., -1.2376e-02,\n",
            "           -1.5467e-01, -2.1070e-02],\n",
            "          [-7.5503e-03, -2.6392e-01,  1.2096e-01,  ...,  8.6665e-02,\n",
            "            1.8046e-01, -1.3749e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.6421e-01, -4.2639e-01, -3.9855e-01,  ..., -2.5122e-01,\n",
            "            1.7734e-01,  9.8222e-02],\n",
            "          [-1.7572e-02, -2.3274e-02,  6.0463e-01,  ..., -2.9696e-01,\n",
            "            1.2191e-01,  7.3964e-02],\n",
            "          [-1.0747e-01, -4.5556e-01,  4.6274e-01,  ..., -1.0968e+00,\n",
            "           -4.9572e-01,  4.1299e-01],\n",
            "          ...,\n",
            "          [-9.9707e-02,  5.2276e-01, -4.0509e-01,  ..., -1.7041e-01,\n",
            "            3.3314e-01,  4.3883e-01],\n",
            "          [-2.6211e-01, -1.9986e-01, -2.3165e-01,  ..., -4.3811e-02,\n",
            "           -4.7824e-01,  8.0248e-01],\n",
            "          [ 1.7068e-01, -2.2554e-01, -1.1389e+00,  ...,  4.0973e-01,\n",
            "            9.1156e-02, -4.9567e-02]],\n",
            "\n",
            "         [[ 1.9740e-01,  7.9281e-02,  6.8351e-01,  ...,  2.9265e-02,\n",
            "            7.9494e-02, -2.1315e-01],\n",
            "          [-2.5018e-02, -7.3537e-01, -7.6833e-02,  ...,  3.9614e-01,\n",
            "            3.4809e-02,  2.2747e-01],\n",
            "          [-9.6095e-01,  5.9519e-01,  5.8126e-01,  ...,  3.9287e-01,\n",
            "           -7.0644e-01, -1.3875e-01],\n",
            "          ...,\n",
            "          [ 7.3506e-02,  8.9560e-01,  4.3113e-01,  ...,  8.2314e-01,\n",
            "            6.1069e-01, -1.4935e-01],\n",
            "          [ 2.7620e-01,  3.9864e-02,  1.5646e-01,  ...,  4.4681e-02,\n",
            "           -3.8767e-01, -2.5358e-01],\n",
            "          [ 3.6420e-02,  1.0181e+00, -6.0966e-01,  ..., -3.9561e-01,\n",
            "           -1.3634e-01, -4.4853e-01]],\n",
            "\n",
            "         [[ 8.6415e-02,  3.4053e-01, -4.5252e-01,  ...,  8.2512e-01,\n",
            "            1.0481e-02,  1.1755e-01],\n",
            "          [ 8.9047e-01,  4.9082e-01, -5.3293e-01,  ...,  6.1054e-02,\n",
            "           -4.5011e-01,  2.0562e-01],\n",
            "          [-1.3444e-02,  1.3708e-01,  2.3633e-01,  ...,  5.4833e-01,\n",
            "           -2.3885e-01, -1.6633e-01],\n",
            "          ...,\n",
            "          [-2.5802e-01,  5.5713e-01,  1.8325e-01,  ...,  2.1149e-01,\n",
            "           -7.6943e-02,  6.3474e-01],\n",
            "          [ 4.7671e-01, -4.4957e-01,  7.6084e-01,  ..., -4.0486e-01,\n",
            "           -5.4569e-01, -3.7457e-01],\n",
            "          [ 4.2488e-01,  2.2536e-02,  6.0892e-01,  ..., -9.7599e-01,\n",
            "            4.2681e-01, -3.7252e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.5837e-02, -1.7066e-01, -5.4601e-03,  ..., -3.8911e-01,\n",
            "           -3.3876e-01,  1.9109e-01],\n",
            "          [-5.2488e-01, -3.5633e-01, -2.7074e-02,  ..., -5.4802e-01,\n",
            "           -9.5788e-02, -1.9383e-01],\n",
            "          [-7.6679e-01,  3.2289e-01,  1.9323e-02,  ...,  5.0960e-01,\n",
            "           -1.7769e-01,  5.0041e-01],\n",
            "          ...,\n",
            "          [-8.0400e-02, -1.4105e-01,  3.1393e-01,  ..., -3.3842e-01,\n",
            "            2.8400e-01, -1.7774e-01],\n",
            "          [-4.1172e-01, -1.0629e+00, -8.2143e-01,  ...,  8.6100e-02,\n",
            "           -9.2566e-01, -3.4723e-01],\n",
            "          [-1.2207e-01, -2.7147e-01,  4.8182e-01,  ..., -9.4704e-01,\n",
            "           -7.7885e-02,  2.6531e-01]],\n",
            "\n",
            "         [[ 1.8921e-01,  5.5508e-01, -1.1166e-01,  ..., -9.5102e-02,\n",
            "           -3.6803e-01, -3.2851e-01],\n",
            "          [ 6.3099e-01,  4.6048e-01, -3.0192e-01,  ...,  1.9346e-01,\n",
            "           -4.8073e-01, -8.1810e-02],\n",
            "          [ 2.2329e-02, -1.3120e+00, -1.1058e+00,  ..., -4.3356e-01,\n",
            "           -3.5904e-02,  1.1005e-01],\n",
            "          ...,\n",
            "          [-4.9215e-01, -5.9900e-01,  1.0123e-01,  ..., -1.1213e+00,\n",
            "           -3.3754e-01, -2.9584e-01],\n",
            "          [ 3.9091e-01,  5.6821e-01, -6.5992e-01,  ...,  3.5089e-01,\n",
            "            1.9844e-01,  1.3443e-01],\n",
            "          [-1.3216e-01,  6.2658e-02,  5.1718e-01,  ...,  4.4307e-01,\n",
            "            2.3062e-01,  5.5051e-01]],\n",
            "\n",
            "         [[ 4.0591e-02,  8.6214e-02, -4.4013e-01,  ...,  5.3273e-01,\n",
            "           -3.0980e-01,  1.0454e-01],\n",
            "          [ 5.0546e-01,  5.0149e-01,  3.9763e-01,  ..., -4.4304e-01,\n",
            "           -1.8761e-01,  2.4560e-01],\n",
            "          [-8.2067e-01, -7.6809e-01, -3.3714e-01,  ...,  8.0348e-01,\n",
            "           -2.9999e-01, -4.2794e-01],\n",
            "          ...,\n",
            "          [-9.3951e-01, -8.1522e-01,  9.2373e-01,  ..., -3.4924e-01,\n",
            "            7.9464e-01,  2.6208e-01],\n",
            "          [ 7.1308e-01,  8.4749e-01, -1.6688e-02,  ..., -1.1829e-01,\n",
            "            2.8179e-02, -4.0855e-01],\n",
            "          [ 4.0675e-01, -2.1566e-01, -4.7606e-01,  ...,  2.6083e-01,\n",
            "            1.6630e-01, -1.5978e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4435e-01, -5.1986e-01,  4.7094e-01,  ..., -4.4084e-01,\n",
            "           -2.4601e-01,  1.8300e-01],\n",
            "          [-3.2819e-02, -1.0570e+00,  3.7986e-01,  ..., -9.4090e-01,\n",
            "           -1.1313e-01,  2.6920e-01],\n",
            "          [ 1.2439e-01,  6.3535e-01,  4.7809e-01,  ...,  5.0112e-01,\n",
            "            1.0039e-01, -5.7281e-01],\n",
            "          ...,\n",
            "          [ 1.4533e-01,  3.6345e-01, -6.3299e-01,  ...,  3.0933e-01,\n",
            "            2.6161e-01,  5.4193e-02],\n",
            "          [ 1.1135e-01, -1.2413e-01,  3.0660e-01,  ...,  6.1954e-03,\n",
            "            7.2704e-04,  1.9485e-01],\n",
            "          [ 9.4220e-02, -6.1014e-01, -5.3790e-01,  ...,  4.5258e-01,\n",
            "            2.1157e-02,  4.1380e-01]],\n",
            "\n",
            "         [[-1.2697e-01, -1.5787e-01,  1.2786e-01,  ...,  2.3943e-01,\n",
            "            9.1322e-02,  2.3914e-01],\n",
            "          [-2.8982e-02, -3.9417e-01,  2.7679e-01,  ..., -5.1555e-01,\n",
            "            3.5547e-01,  4.3406e-01],\n",
            "          [-1.5152e-01, -1.8033e-01,  4.1953e-01,  ...,  7.2275e-01,\n",
            "           -7.9191e-01, -2.5785e-01],\n",
            "          ...,\n",
            "          [-6.0271e-01,  8.1569e-02, -5.1506e-01,  ...,  1.0358e+00,\n",
            "           -4.0685e-01,  2.0710e-01],\n",
            "          [ 1.0319e-01,  1.0535e-01, -4.3388e-01,  ..., -2.6849e-01,\n",
            "            2.0145e-01,  3.0373e-01],\n",
            "          [-9.0023e-02,  4.7338e-01, -8.9123e-01,  ...,  5.0811e-01,\n",
            "           -4.7756e-01, -1.0385e-01]],\n",
            "\n",
            "         [[ 4.7349e-01,  2.6914e-01,  4.4535e-02,  ...,  1.2312e-01,\n",
            "           -8.9164e-02,  6.6163e-01],\n",
            "          [-2.6460e-01,  1.2045e-01,  1.3562e+00,  ..., -2.5833e-01,\n",
            "           -6.4887e-01, -4.2159e-02],\n",
            "          [ 1.5043e-01, -8.4646e-01,  4.0650e-01,  ...,  7.7593e-01,\n",
            "            2.5707e-01,  7.8924e-01],\n",
            "          ...,\n",
            "          [ 5.3239e-01, -1.1083e+00, -4.8372e-01,  ...,  5.6596e-02,\n",
            "           -7.0302e-01,  2.1072e-01],\n",
            "          [-2.9245e-01, -1.6187e-01,  6.9332e-02,  ..., -2.9533e-02,\n",
            "           -8.1247e-01,  3.1765e-01],\n",
            "          [ 1.6763e-01, -2.4632e-01,  3.0521e-01,  ...,  1.3726e+00,\n",
            "            7.4982e-01,  3.3178e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.3024e-01, -1.7468e-01, -9.4247e-01,  ..., -1.8058e-01,\n",
            "            1.2461e-01, -1.3502e-01],\n",
            "          [-2.3514e-02,  1.9788e-01, -8.3454e-01,  ...,  1.1793e-02,\n",
            "           -3.1379e-01,  5.5524e-02],\n",
            "          [ 8.4154e-02, -5.6799e-02,  2.4842e-02,  ..., -9.3768e-01,\n",
            "            4.9062e-01,  3.0001e-01],\n",
            "          ...,\n",
            "          [ 5.9855e-01, -3.4982e-02,  9.2915e-01,  ...,  4.1538e-01,\n",
            "           -6.7937e-02, -6.7507e-01],\n",
            "          [ 5.0099e-01, -1.6475e-01, -7.1534e-01,  ...,  1.9558e-01,\n",
            "           -3.9909e-01,  9.2616e-01],\n",
            "          [ 8.4203e-02,  6.5591e-02,  5.4825e-01,  ..., -4.2259e-01,\n",
            "            1.3219e-02, -1.3111e-01]],\n",
            "\n",
            "         [[ 1.3577e-01,  1.2517e-01, -3.4078e-01,  ..., -1.2178e-01,\n",
            "            1.5078e-01, -1.1939e-01],\n",
            "          [-6.7817e-02,  4.0226e-01, -1.5569e-01,  ...,  5.5431e-01,\n",
            "           -2.3131e-01, -7.1597e-01],\n",
            "          [ 2.5851e-01, -7.1655e-01, -6.7987e-01,  ...,  2.2081e-01,\n",
            "           -6.6585e-01,  9.0581e-01],\n",
            "          ...,\n",
            "          [ 4.1795e-01, -6.8096e-01, -3.0983e-01,  ..., -3.4992e-01,\n",
            "            8.4631e-01, -1.7039e-01],\n",
            "          [-6.9209e-01, -1.8767e-01, -3.6137e-01,  ..., -3.4849e-01,\n",
            "            2.1529e-01, -1.8619e-01],\n",
            "          [-3.8960e-01,  9.4091e-02, -2.4548e-02,  ..., -1.2502e-01,\n",
            "           -3.0929e-01, -4.9328e-01]],\n",
            "\n",
            "         [[-1.5974e-01,  2.9720e-01, -2.3236e-01,  ...,  2.0474e-02,\n",
            "            5.5103e-01,  5.7581e-01],\n",
            "          [-4.7757e-01,  1.7274e-01,  8.7471e-01,  ..., -1.5355e-02,\n",
            "           -3.7747e-01, -2.7276e-01],\n",
            "          [-4.6183e-01, -4.8618e-01,  6.1105e-01,  ...,  3.2745e-02,\n",
            "           -5.4500e-01, -6.6926e-01],\n",
            "          ...,\n",
            "          [-2.2069e-01,  3.2906e-01, -1.2192e-01,  ...,  1.3140e-01,\n",
            "           -4.6718e-01,  4.4702e-01],\n",
            "          [ 2.7412e-01,  9.5402e-02,  3.1617e-01,  ...,  1.7688e-01,\n",
            "           -2.4297e-01,  3.0949e-01],\n",
            "          [-2.0719e-01, -3.6209e-01,  4.3095e-02,  ...,  6.6690e-01,\n",
            "           -5.8108e-02, -1.0983e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9519e-01,  1.1600e-01, -5.7790e-01,  ...,  2.4529e-02,\n",
            "           -2.2670e-02,  5.0774e-03],\n",
            "          [-4.3796e-01,  5.9861e-01, -2.6893e-01,  ..., -3.9159e-01,\n",
            "           -4.4159e-01, -7.1350e-01],\n",
            "          [ 2.8215e-01,  2.4778e-01, -2.4957e-01,  ...,  7.4118e-02,\n",
            "           -6.6876e-01,  8.4297e-01],\n",
            "          ...,\n",
            "          [-1.5271e-01, -3.4544e-01,  6.6678e-01,  ...,  8.1018e-01,\n",
            "            5.1845e-01, -5.6910e-01],\n",
            "          [-3.2160e-01,  2.4870e-01, -2.9783e-01,  ..., -4.7394e-01,\n",
            "            2.6374e-01, -1.6939e-01],\n",
            "          [-1.9482e-01, -4.6092e-01,  4.6125e-01,  ..., -1.0250e+00,\n",
            "           -2.5311e-01,  4.2112e-01]],\n",
            "\n",
            "         [[ 1.3854e-01, -1.0336e-01,  4.6009e-01,  ..., -3.5672e-02,\n",
            "            5.8946e-01, -2.9488e-01],\n",
            "          [ 6.9686e-02,  5.4132e-01,  5.1624e-01,  ...,  1.5490e-01,\n",
            "            4.2459e-01,  1.3752e-02],\n",
            "          [ 1.3940e-01,  1.8249e-01,  6.9012e-02,  ..., -6.3720e-02,\n",
            "            5.7697e-01,  2.9836e-01],\n",
            "          ...,\n",
            "          [-9.9138e-03, -9.9942e-01, -1.4193e+00,  ..., -8.9088e-01,\n",
            "           -1.9834e-01,  1.0167e-01],\n",
            "          [-6.7776e-01,  5.3730e-01,  3.1283e-02,  ..., -2.1992e-01,\n",
            "            4.4488e-01, -6.0772e-01],\n",
            "          [-9.4033e-02,  6.4151e-02, -1.2787e-02,  ..., -4.7747e-02,\n",
            "           -1.3967e-01,  5.0220e-01]],\n",
            "\n",
            "         [[-1.5438e-01,  3.9237e-01, -7.2468e-01,  ...,  1.8526e-02,\n",
            "            1.9032e-01,  2.4782e-01],\n",
            "          [-3.3531e-01,  2.0567e-01,  4.7329e-01,  ...,  2.0448e-01,\n",
            "           -2.2359e-01, -2.0912e-01],\n",
            "          [-4.2052e-02,  6.0895e-01, -1.6246e-01,  ..., -8.4996e-01,\n",
            "           -9.1922e-01,  1.2476e-01],\n",
            "          ...,\n",
            "          [ 1.9930e-01,  8.3333e-02, -7.3946e-01,  ...,  1.0080e-01,\n",
            "            3.7152e-01, -4.2062e-01],\n",
            "          [ 3.7029e-01,  2.0337e-01,  3.8233e-01,  ...,  3.3170e-01,\n",
            "            5.3868e-01,  1.4511e-01],\n",
            "          [ 1.1997e-01, -4.2794e-02,  7.0980e-02,  ..., -7.9670e-02,\n",
            "           -1.0082e+00,  3.5384e-02]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
          ]
        }
      ],
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) # dilation = 패딩 사이의 간격\n",
        "\n",
        "input = torch.randn(20, 16, 50 ,100)\n",
        "print(input)\n",
        "output = m(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RLqGbclbp3_N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 26, 100])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYeGAJEuneqW"
      },
      "source": [
        "### nn.functional 패키지\n",
        "\n",
        "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
        "\n",
        "- 예시)\n",
        "  - Convolution functions\n",
        "\n",
        "  - Pooling functions\n",
        "  \n",
        "  - Non-linear activation functions\n",
        "\n",
        "  - Normalization functions\n",
        "\n",
        "  - Linear functions\n",
        "\n",
        "  - Dropout functions\n",
        "  \n",
        "  - Sparse functions\n",
        "  \n",
        "  - Distance functions\n",
        "\n",
        "  - Loss functions\n",
        "  - ..\n",
        "\n",
        "- https://pytorch.org/docs/stable/nn.functional.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NpwbO9Dhpflm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYaJ5aLqKed"
      },
      "source": [
        "- Convolution Layer 예시 (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GAWLQE2GouHP"
      },
      "outputs": [],
      "source": [
        "filters = torch.randn(8, 4, 3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lWmSlFBrpms1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 5, 5])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.randn(1, 4, 5, 5)\n",
        "conv = F.conv2d(inputs, filters, padding=1)\n",
        "conv.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wah4RsmgrRDP"
      },
      "source": [
        "## Torchvision\n",
        "\n",
        "- `transforms`: 전처리할 때 사용하는 메소드\n",
        "\n",
        "- `transforms`에서 제공하는 클래스 이외에  \n",
        "  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
        "  \n",
        "  - 아래의 코드에서 다양한 전처리 기술 확인  \n",
        "    https://pytorch.org/docs/stable/torchvision/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "akvq4QWmqSil"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKu5mzyTs-Qj"
      },
      "source": [
        "- 예시)\n",
        "  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n",
        "\n",
        "  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
        "\n",
        "  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n",
        "   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y6K7FH-Rs9my"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4l1GvIlslKa"
      },
      "source": [
        "## utils.data\n",
        "\n",
        "- `Dataset`에는 다양한 데이터셋이 존재  \n",
        "  - MNIST, CIFAR10, ...\n",
        "\n",
        "- `DataLoader`, `Dataset`을 통해  \n",
        "  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1wsZKY7-s2Vv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lldpI2lquBu3"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.MNIST(root='/content/',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='/content/',\n",
        "                                      train=False,\n",
        "                                      download=True,\n",
        "                                      transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fKddZnT1uQmT"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2) # 배치 사이즈만큼 dataloader가 데이터를 가져옴\n",
        "test_loader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxymquLxeo8"
      },
      "source": [
        "- `batch_size`만큼 데이터를 하나씩 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hvgMIyF6uUuU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.shape, labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUC0a0aw6OM"
      },
      "source": [
        "<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n",
        "\n",
        "- `channel first`\n",
        "\n",
        "- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhylD3iyFYr"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "C9hAQmQlul8P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zDcUY6o4xUQp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch_image = torch.squeeze(images[0])\n",
        "torch_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MZmPWiGbxoiW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = torch_image.numpy()\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AUOdd4UaxaXO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label = labels[1].numpy()\n",
        "label.shape # 스칼라이므로 없다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PDQfjw4wxr1z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(6, dtype=int64)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JDCVw59ax3-A"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title(label)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcWQlxzihtS"
      },
      "source": [
        "## 각 Layer 설명"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IGXn1_weif5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kJ3heBi26y"
      },
      "source": [
        "### nn.Conv2d\n",
        "\n",
        "- `in_channels`: channel의 갯수\n",
        "\n",
        "- `out_channels`: 출력 채널의 갯수\n",
        "\n",
        "- `kernel_size`: 커널(필터) 사이즈\n",
        "\n",
        "- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RcHJguyFipTl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iWiJbViHjFG0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = nn.Conv2d(1, 20, 5, 1).to(torch.device('cpu'))\n",
        "layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWYFm2xjUeN"
      },
      "source": [
        "- `wegiht`확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "za0enRbyjPzV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 1, 5, 5])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight = layer.weight\n",
        "weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZcTU2gjiCX"
      },
      "source": [
        "- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9eN_oUBkjT85"
      },
      "outputs": [],
      "source": [
        "weight = weight.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kwso9tsijmz8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 1, 5, 5)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight = weight.numpy()\n",
        "weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mUegf6HPjdPl"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(weight[0, 0, :, :], 'jet')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DMeTOqVmcdWa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cvolnNsscdHs"
      },
      "outputs": [],
      "source": [
        "input_image = torch.unsqueeze(images[0], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NLOAfD5mjup1"
      },
      "outputs": [],
      "source": [
        "output_data = layer(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r50wFkl6j1sY"
      },
      "outputs": [],
      "source": [
        "output = output_data.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZiIp-frJj2Hl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 20, 24, 24)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_arr = output.numpy()\n",
        "output_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uOHMu-UQkW3a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x2160 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 30))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.title(\"Input\")\n",
        "plt.imshow(image, 'gray')\n",
        "plt.subplot(132)\n",
        "plt.title('Weight')\n",
        "plt.imshow(weight[0, 0, :, :], 'jet')\n",
        "plt.subplot(133)\n",
        "plt.title(\"Output\")\n",
        "plt.imshow(output_arr[0, 0, :, :], 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCqGmH_kwHm"
      },
      "source": [
        "### Pooling\n",
        "- `F.max_pool2d` \n",
        "  - `stride`\n",
        "\n",
        "  - `kernel_size`\n",
        "\n",
        "- `torch.nn.MaxPool2d` 도 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AYqPrLH1kxQl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tvI8W_8Yk81S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 12, 12])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool = F.max_pool2d(output, 2, 2)\n",
        "pool.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3HK4FulCaJ"
      },
      "source": [
        "- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "fseB_qlflBta"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 20, 12, 12)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool_arr = pool.numpy()\n",
        "pool_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6w8DQnNtlNCq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 15))\n",
        "plt.subplot(121)\n",
        "plt.title('Input')\n",
        "plt.imshow(image, 'gray')\n",
        "plt.subplot(122)\n",
        "plt.title('Output')\n",
        "plt.imshow(pool_arr[0, 0, :, :], 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RVioKwlbH1"
      },
      "source": [
        "### Linear\n",
        "- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Kwcedadrlcbl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = torch.from_numpy(image)\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_mYQy4I3lmAm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flatten = image.view(1, 28 * 28)\n",
        "flatten.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6wgSmY0Zlofk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin = nn.Linear(784, 10)(flatten)\n",
        "lin.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LcJFqf0alsxr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.6141,  0.0517, -0.8529, -0.1260, -0.3787, -0.4828,  0.5421, -0.7252,\n",
              "          0.5936, -0.9003]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ewEpebSVluHz"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(lin.detach().numpy(), 'jet')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjPKDKRl3CV"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "obhBb3O-lzbs"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    flatten = image.view(1, 28*28)\n",
        "    lin = nn.Linear(784, 10)(flatten)\n",
        "    softmax = F.softmax(lin, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ljgOEyNMmBEE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0288, 0.0974, 0.1947, 0.1057, 0.0938, 0.1706, 0.0946, 0.0966, 0.0808,\n",
              "         0.0369]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "18ymFSRAmBo7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.sum(softmax.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh13Bnj5wEN"
      },
      "source": [
        "### F.relu\n",
        "\n",
        "- ReLU 함수를 적용하는 레이어\n",
        "\n",
        "- `nn.ReLU`로도 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "D4VFePpR9_Ak"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 28, 28])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.randn(4, 3, 28, 28).to(device)\n",
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "1lKlSiaY5wZW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 20, 24, 24])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = nn.Conv2d(3, 20, 5, 1).to(device)\n",
        "output = F.relu(layer(inputs))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "- `import torch.optim as optim`\n",
        "\n",
        "- `model`의 파라미터를 업데이트\n",
        "\n",
        "- 예시)\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "- `.zero_grad()`로 초기화\n",
        "- `.step()`으로 업데이트\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "_9 파이토치(PyTorch) 기초.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
